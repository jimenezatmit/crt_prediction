{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "156c7652",
   "metadata": {},
   "source": [
    "# Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1310f8c9",
   "metadata": {},
   "source": [
    "1. Walk through the entire notebook, section by section, to run the entire pipeline for all three kinds of prediction. There are six sections total, including one supplemental module.\n",
    "    1. Set up\n",
    "    2. Individual feature\n",
    "    3. Umbrella features\n",
    "    4. Combined features (individual)\n",
    "    5. Combined features (umbrella)\n",
    "    6. *(Supplemental) Informative features*\n",
    "2. **Yellow cells**: Run cell *without* changing code \n",
    "3. **Red cells**: Complete TODOs and run cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6d9b01",
   "metadata": {},
   "source": [
    "# 1. Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720c305",
   "metadata": {},
   "source": [
    "**1.1 Import relevant packages**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35159a43",
   "metadata": {},
   "source": [
    "In this section, import all relevant notebooks containing helper functions and packages (may take a few minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "930288d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /Users/anjimenez/HCL/crt_project/pipeline/pipeline_components/general.ipynb\n",
      "importing Jupyter notebook from /Users/anjimenez/HCL/crt_project/pipeline/pipeline_components/model_functions.ipynb\n",
      "importing Jupyter notebook from /Users/anjimenez/HCL/crt_project/pipeline/pipeline_components/plot.ipynb\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#fff9e9';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import once, to import functions from other notebooks\n",
    "import import_ipynb\n",
    "\n",
    "# general packages\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import pickle\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import random\n",
    "import statistics\n",
    "import json\n",
    "import _pickle as pickle\n",
    "import copy\n",
    "\n",
    "# import pipeline components\n",
    "import pipeline_components.general as general\n",
    "import pipeline_components.model_functions as model \n",
    "import pipeline_components.plot as plot \n",
    "\n",
    "general.set_background('#fff9e9')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc79822f",
   "metadata": {},
   "source": [
    "**1.2 Define global variables and paths**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97285d6e",
   "metadata": {},
   "source": [
    "In this section, we define the global variables and paths that will be used throughout the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9eb4c1",
   "metadata": {},
   "source": [
    "<font color='green'>**Variable Descriptions**</font>\n",
    "1. **MY_TARGET** (string): name of target variable (i.e. CRT score)\n",
    "    1. Use \"CRT_ACC\" if CRT contains both numeric and conceptual questions\n",
    "    2. Use \"CRT_numeric\" if CRT contains just numeric questions\n",
    "    3. Use \"CRT_conceptual\" if CRT contains just conceptual questions\n",
    "2. **DATAFRAME_TYPE** (string): description of how NaN values are dealt with in the dataframe\n",
    "    1. Use \"Complete\" if NaN values were dropped\n",
    "    2. Use \"Imputed\" if NaN values were imputed\n",
    "    3. Use \"Full\" if NaN values remain as NaNs\n",
    "3. **MY_DATE** (string): month and day of run as MM_DD\n",
    "4. **MY_CROSS_VAL** (integer): the number of folds for cross-validation during prediction\n",
    "5. **MY_TEXT_FEATURES** (list of strings): list of text feature names\n",
    "\n",
    "<font color='blue'>**Path Descriptions**</font>\n",
    "1. **ROOT_DIR** (string): path to root directory, which is /pipeline\n",
    "2. **RESULTS_FOLDER_NAME** (string): name of folder that stores pipeline results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12dd9228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#efe1e1';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: set variables\n",
    "MY_TARGET = 'CRT_ACC' # {\"CRT_ACC\", \"CRT_numerical\", \"CRT_conceptual\"'}\n",
    "DATAFRAME_TYPE = 'Complete' # {\"Complete\", \"Imputed\", \"Full\"}\n",
    "MY_DATE = '04_11'\n",
    "MY_CROSS_VAL = 5\n",
    "\n",
    "# TODO: set text features\n",
    "MY_TEXT_FEATURES = ['text', 'domains', 'followees', 'mentions', 'hashtags', 'bio', 'follower_bios', 'followee_bios']\n",
    "\n",
    "general.set_background('#efe1e1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "135d3ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#fff9e9';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run this cell to create results and plots folders if they do not exist\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath('__file__')) + \"/\" \n",
    "RESULTS_FOLDER_NAME = 'results/{}/{}/{}/'.format(MY_DATE, DATAFRAME_TYPE.lower(), MY_TARGET) \n",
    "\n",
    "PLOT_FOLDER_NAME = 'results/{}/plots/'.format(MY_DATE)\n",
    "\n",
    "isExist = os.path.exists(RESULTS_FOLDER_NAME)\n",
    "if not isExist:\n",
    "    os.makedirs(RESULTS_FOLDER_NAME)\n",
    "\n",
    "isExist = os.path.exists(PLOT_FOLDER_NAME)\n",
    "if not isExist:\n",
    "    os.makedirs(PLOT_FOLDER_NAME)\n",
    "    \n",
    "general.set_background('#fff9e9')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa5545d",
   "metadata": {},
   "source": [
    "**1.3 Read data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0870923",
   "metadata": {},
   "source": [
    "Data should already be pre-processed and stored in the **/data/master** subfolder. See *data_processing.ipynb* for instructions on how dataframe should be properly formatted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553c3a9b",
   "metadata": {},
   "source": [
    "<font color='blue'>**Path Descriptions**</font>\n",
    "1. **DATA_PATH** (string): path to file containing dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "743d2375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#efe1e1';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: set path to dataframe\n",
    "DATA_PATH = 'data/master/data_full.parquet' # Full dataset\n",
    "# DATA_PATH = 'data/master/data_complete.parquet' # Complete dataset\n",
    "\n",
    "general.set_background('#efe1e1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "94031f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All feature names:\n",
      "\n",
      "screen_name                   followees_count               CRT_ACC\n",
      "political                     has_location                  is_protected\n",
      "follower_followers_avg        bio                           insight\n",
      "followee_tweets_avg           hashtags_count                hashtags_avg_length\n",
      "neg_emotion                   age                           favorites_avg\n",
      "domains_count_unique          domains                       follower_bios\n",
      "follower_followees_avg        CRT_numeric                   mentions_count\n",
      "inhibit                       url_exist                     followees\n",
      "follower_media_avg            statuses_count                domains_count\n",
      "pos_emotion                   followee_followers_avg        creation_time_of_day\n",
      "follower_likes_avg            hashtags                      has_profile_image\n",
      "screen_name_char              follower_verified_score       followee_bios\n",
      "followee_verified_score       bio_char                      moral\n",
      "CRT_conceptual                followee_likes_avg            followers_count\n",
      "mentions_count_unique         follower_tweets_avg           text\n",
      "followee_followees_avg        relig                         outlet_score\n",
      "listed_count                  mentions                      favorites_given_count\n",
      "bot_score                     screen_name_digits            days_on_twitter\n",
      "\n",
      "Number of participants: 1808 , Number of features: 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#fff9e9';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run this cell to read the dataframe and print basic information about the data\n",
    "data = pq.read_table(DATA_PATH).to_pandas()\n",
    "\n",
    "target_feats = []\n",
    "for i in data.columns:\n",
    "    if i != 'screen_name' and i != 'age' and not i.startswith('CRT'):\n",
    "        target_feats.append(i)\n",
    "\n",
    "print(\"All feature names:\\n\")\n",
    "for a,b,c in zip(data.columns.values[::3],data.columns.values[1::3],data.columns.values[2::3]):\n",
    "    print('{:<30}{:<30}{:<}'.format(a,b,c))\n",
    "print(\"\\nNumber of participants:\", data.shape[0], \", Number of features:\", len(target_feats))\n",
    "\n",
    "general.set_background('#fff9e9')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4942bf6f",
   "metadata": {},
   "source": [
    "**1.4 Define umbrella features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f33e1",
   "metadata": {},
   "source": [
    "Individual features can be combined to generate umbrella features: feature groups containing related features. For instance, hashtags, hashtags count, and hashtags average length all contain information related to hashtags and are grouped into one umbrella feature.\n",
    "\n",
    "In this section, we define umbrella features to test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "a9c1682b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#efe1e1';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: set umbrella features\n",
    "profile_features = [\n",
    "    'creation_time_of_day',\n",
    "    'url_exist',\n",
    "    'screen_name_char', \n",
    "    'has_profile_image',\n",
    "    'days_on_twitter',\n",
    "    'has_location',\n",
    "    'bio_char',\n",
    "    'bio',\n",
    "    'bot_score',\n",
    "    'bio_char',\n",
    "    'is_protected',\n",
    "    'listed_count',\n",
    "    'screen_name_digits',\n",
    "    'favorites_avg',\n",
    "    'favorites_given_count'\n",
    "]\n",
    "\n",
    "tweet_features = [\n",
    "    'text', \n",
    "    'statuses_count'\n",
    "]\n",
    "\n",
    "emotional_features = [\n",
    "    'insight',\n",
    "    'inhibit', \n",
    "    'relig', \n",
    "    'pos_emotion',\n",
    "    'neg_emotion',\n",
    "    'moral',\n",
    "    'political'\n",
    "]\n",
    "\n",
    "followee_features = []\n",
    "for i in target_feats:\n",
    "    if i.startswith('followee'):\n",
    "        followee_features.append(i)\n",
    "\n",
    "follower_features = []\n",
    "for i in target_feats:\n",
    "    if i.startswith('follower'):\n",
    "        follower_features.append(i)\n",
    "        \n",
    "hashtag_features = []\n",
    "for i in target_feats:\n",
    "    if i.startswith('hashtag'):\n",
    "        hashtag_features.append(i)\n",
    "\n",
    "mention_features = []\n",
    "for i in target_feats:\n",
    "    if i.startswith('mention'):\n",
    "        mention_features.append(i)\n",
    "\n",
    "domain_features = ['outlet_score']\n",
    "for i in target_feats:\n",
    "    if i.startswith('domain'):\n",
    "        domain_features.append(i)\n",
    "\n",
    "# TODO: define combination features (combinations of umbrella features)\n",
    "all_text = domain_features + mention_features + tweet_features + hashtag_features + emotional_features\n",
    "all_text_words = ['domains', 'hashtags', 'text']\n",
    "all_text_addendums = ['domains', 'hashtags', 'mentions']\n",
    "all_friends = follower_features + followee_features\n",
    "\n",
    "# TODO: create list of umbrella features and umbrella feature names\n",
    "all_umbrella_features = [\n",
    "    domain_features, \n",
    "    mention_features, \n",
    "    tweet_features, \n",
    "    follower_features, \n",
    "    followee_features, \n",
    "    hashtag_features, \n",
    "    profile_features, \n",
    "    emotional_features, \n",
    "    all_text, \n",
    "    all_friends, \n",
    "    all_text_words, \n",
    "    all_text_addendums\n",
    "]\n",
    "\n",
    "all_umbrella_features_names = [\n",
    "    'domain_features', \n",
    "    'mention_features', \n",
    "    'text_features', \n",
    "    'follower_features', \n",
    "    'followee_features', \n",
    "    'hashtag_features', \n",
    "    'profile_features', \n",
    "    'emotional_features', \n",
    "    'all_text', \n",
    "    'all_friends', \n",
    "    'all_text_words', \n",
    "    'all_text_addendums'\n",
    "]\n",
    "\n",
    "general.set_background('#efe1e1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb1fde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to generate a dictionary mapping umbrella feature name to features\n",
    "combined_feats_dict = {}\n",
    "for i in range(len(all_umbrella_features)):\n",
    "    combined_feats_dict[all_umbrella_features_names[i]] = all_umbrella_features[i]\n",
    "    \n",
    "general.set_background('#fff9e9')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bb6ef6",
   "metadata": {},
   "source": [
    "# 2. Individual Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d5afae",
   "metadata": {},
   "source": [
    "In this section, we determine which individual features are most predictive for CRT score. This module performs the following, in order: \n",
    "1. Transform features\n",
    "    1. *For text features*: Transform feature using TF-IDF and TruncatedSVD\n",
    "    2. *For quantitative features*: Log transform if skew is large and standardize\n",
    "2. Split data into train and test set \n",
    "3. Perform feature selection with ElasticNetCV\n",
    "4. Predict CRT on test set with model of choice and cross-validation\n",
    "5. Average results over all splits\n",
    "6. Plot and save results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2889d13a",
   "metadata": {},
   "source": [
    "<font color='green'>**Variable Descriptions**</font>\n",
    "1. **MY_MODEL_INDV** (string): name of model of choice\n",
    "    1. Use \"ridge\" for Ridge model\n",
    "    2. Use \"lasso\" for LASSO model\n",
    "    3. Use \"rfr\" for Random Forests Regressor model\n",
    "2. **MY_PARAMS_INDV** (dictionary): dictionary of parameters for model of choice, following the formatting directions below:\n",
    "    1. Keys are structured \"X__Y\" where X is either \"model\" or \"poly\" and Y is the parameter name, separated by a double underscore\n",
    "        1. Use \"model\" as X to set parameters for the model of choice, which is either Ridge, LASSO, or Random Forests\n",
    "        2. Use \"poly\" as X to set degree for PolynomialFeatures, which captures cross-feature interactions\n",
    "        3. The parameter name Y must match the parameter name in the specs\n",
    "            1. [Ridge specs](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "            2. [LASSO specs](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)\n",
    "            3. [Random Forests specs](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n",
    "            4. [PolynomialFeatures specs](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)\n",
    "    2. Values are a list of parameter values to try in order to find the optimal value during cross-validation\n",
    "        1. List lengths must be equal to or greater than 1 \n",
    "3. **MY_SPLITS_INDV** (list or integer): data splits\n",
    "    1. List of integers: list of random states for train/test split\n",
    "    2. Integer: Randomly generates a list of random states the size of integer\n",
    "4. **MY_MINDF_INDV** (integer): min_df parameter in TF-IDF\n",
    "5. **MY_MAXDF_INDV** (integer): max_df parameter in TF-IDF\n",
    "6. **MY_TEST_SIZE_INDV** (float): size of test set out of 1.0\n",
    "7. **MY_N_COMPONENTS_INDV** (integer): n_components parameter in TruncatedSVD\n",
    "4. **MY_TITLE_INDV** (string\n",
    "): title for saving and plotting results\n",
    "\n",
    "<font color='blue'>**Path Descriptions**</font>\n",
    "1. **RESULTS_FOLDER_INDIVIDUAL** (string): name of folder that stores individual feature results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d9bd057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#efe1e1';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: set variables and paths\n",
    "MY_MODEL_INDV = 'ridge'\n",
    "MY_PARAMS_INDV = {'model__alpha': np.logspace(-5, 5, 100)}\n",
    "MY_SPLITS_INDV = range(0, 50)\n",
    "MY_MINDF_INDV = 10\n",
    "MY_MAXDF_INDV = 0.99\n",
    "MY_TEST_SIZE_INDV = 0.1\n",
    "MY_N_COMPONENTS_INDV = 50\n",
    "MY_TITLE_INDV = 'Individual Features'\n",
    "\n",
    "RESULTS_FOLDER_INDIVIDUAL = ROOT_DIR + RESULTS_FOLDER_NAME + 'individual_{}/'.format(MY_MODEL_INDV)\n",
    "\n",
    "general.set_background('#efe1e1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "111a3dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#fff9e9';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run this cell to store results\n",
    "state_dict_individual = {\n",
    "    'model': MY_MODEL_INDV, \n",
    "    'params': MY_PARAMS_INDV, \n",
    "    'splits': MY_SPLITS_INDV,\n",
    "    'mindf': MY_MINDF_INDV,\n",
    "    'maxdf': MY_MAXDF_INDV,\n",
    "    'test_size': MY_TEST_SIZE_INDV,\n",
    "    'n_components': MY_N_COMPONENTS_INDV,\n",
    "}\n",
    "\n",
    "r_dict = {}\n",
    "p_dict = {}\n",
    "score_dict = {}\n",
    "individual_results_df = pd.DataFrame({})\n",
    "\n",
    "general.set_background('#fff9e9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32c0bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to find best individual features \n",
    "\n",
    "for feat in target_feats:\n",
    "\n",
    "    print(feat)\n",
    "    \n",
    "    # determine splits \n",
    "    splits = model.get_splits(MY_SPLITS_INDV)\n",
    "                          \n",
    "    # create X and Y from data \n",
    "    X_original = data[feat].dropna()\n",
    "    Y_original = data[MY_TARGET]\n",
    "    \n",
    "    # set r, p, score sums to 0\n",
    "    total_r = []\n",
    "    total_p = []\n",
    "    total_score = []\n",
    "    \n",
    "    if feat in MY_TEXT_FEATURES:\n",
    "        X, Y, na_count = model.transform_feature(data, feat, MY_TARGET, my_max_df=MY_MAXDF_INDV, \n",
    "                                                 my_min_df=MY_MINDF_INDV, \n",
    "                                 my_n_components=MY_N_COMPONENTS_INDV)\n",
    "    else:\n",
    "        X, Y, na_count = model.transform_feature(data, feat, MY_TARGET)\n",
    "            \n",
    "    # average over all splits \n",
    "    for s in splits:\n",
    "        \n",
    "        # split data into train test set\n",
    "        X_train, X_test, Y_train, Y_test = model.split_data(X, Y, MY_TARGET, MY_TEST_SIZE_INDV, s)\n",
    "        \n",
    "        # feature selection with ElasticNet on train set \n",
    "        X_train, X_test, Y_train, Y_test = model.feature_selection(X_train, X_test, Y_train, Y_test, 'median')\n",
    "        \n",
    "        # predict on test set \n",
    "        results = model.predict(X_train, X_test, Y_train, Y_test, MY_MODEL_INDV, MY_PARAMS_INDV, MY_CROSS_VAL)\n",
    "        \n",
    "        print(results)\n",
    "        \n",
    "        # add to r, p totals\n",
    "        total_r.append(results['r'])\n",
    "        total_p.append(results['p'])\n",
    "        total_score.append(results['r2'])\n",
    "    \n",
    "    # add individual feature results to results dataframe\n",
    "    f_results = model.create_results(feat, na_count, total_r, total_p, total_score)\n",
    "    individual_results_df = individual_results_df.append(f_results, ignore_index = True)\n",
    "    \n",
    "    r_dict[feat] = total_r\n",
    "    p_dict[feat] = total_p\n",
    "    score_dict[feat] = total_score\n",
    "\n",
    "# create and show plots\n",
    "plot, chart = model.create_plotly_individual(individual_results_df, MY_TARGET, \n",
    "                                             DATAFRAME_TYPE, MY_MODEL_INDV, MY_TITLE_INDV)\n",
    "chart.show()\n",
    "\n",
    "# save results and plots \n",
    "model.save_results(RESULTS_FOLDER_INDIVIDUAL, MY_TITLE_INDV.lower(), individual_results_df, \n",
    "             plot, chart, state_dict_individual)\n",
    "plot.individual_plot(individual_results_df, MY_TEXT_FEATURES, PLOT_FOLDER_NAME, MY_MODEL_INDV, DATAFRAME_TYPE)\n",
    "\n",
    "general.set_background('#fff9e9')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eec841f",
   "metadata": {},
   "source": [
    "# 3. Umbrella Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ee0ab1",
   "metadata": {},
   "source": [
    "*Variable and path definitions are similar to that of individual features prediction in Section 2.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e9ba093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#efe1e1';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: set variables and paths\n",
    "MY_MODEL_UMB = 'ridge'\n",
    "MY_PARAMS_UMB = {'model__alpha': np.logspace(-5, 5, 100)}\n",
    "MY_SPLITS_UMB = range(0, 50)\n",
    "MY_MINDF_UMB = 10\n",
    "MY_MAXDF_UMB = 0.99\n",
    "MY_TEST_SIZE_UMB = 0.1\n",
    "MY_N_COMPONENTS_UMB = 50\n",
    "MY_TITLE_UMB = 'Umbrella Features'\n",
    "\n",
    "RESULTS_FOLDER_UMBRELLA = ROOT_DIR + RESULTS_FOLDER_NAME + 'umbrella_{}/'.format(MY_MODEL_UMB)\n",
    "\n",
    "general.set_background('#efe1e1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d87310c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#fff9e9';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run this cell to store results\n",
    "state_dict_umbrella = {\n",
    "    'model': MY_MODEL_UMB, \n",
    "    'params': MY_PARAMS_UMB, \n",
    "    'splits': MY_SPLITS_UMB,\n",
    "    'mindf': MY_MINDF_UMB,\n",
    "    'maxdf': MY_MAXDF_UMB,\n",
    "    'test_size': MY_TEST_SIZE_UMB,\n",
    "    'n_components': MY_N_COMPONENTS_UMB,\n",
    "}\n",
    "\n",
    "r_dict = {}\n",
    "p_dict = {}\n",
    "score_dict = {}\n",
    "umbrella_results_df = pd.DataFrame({})\n",
    "\n",
    "general.set_background('#fff9e9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dd9d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to find best umbrella features \n",
    "\n",
    "for j in range(len(all_features)):\n",
    "\n",
    "    feature = all_features[j]\n",
    "    feature_name = all_features_names[j]\n",
    "    \n",
    "    print(feature)\n",
    "    \n",
    "    # determine splits \n",
    "    splits = model.get_splits(MY_SPLITS_UMB)\n",
    "                          \n",
    "    # create X and Y from data \n",
    "    X_original = data[feature]\n",
    "    Y_original = data[MY_TARGET]\n",
    "    \n",
    "    # set r, p, score sums to 0\n",
    "    total_r = []\n",
    "    total_p = []\n",
    "    total_score = []\n",
    "    \n",
    "    # transform text and quantitative data \n",
    "    X = []\n",
    "    for feat in feature:\n",
    "        if feat in MY_TEXT_FEATURES:\n",
    "            X_new, Y_new, na_count = model.transform_feature(data, feat, MY_TARGET, my_max_df=MY_MAXDF_UMB, \n",
    "                                                             my_min_df=MY_MINDF_UMB, \n",
    "                                     my_n_components=MY_N_COMPONENTS_UMB)\n",
    "        else:\n",
    "            X_new, Y_new, na_count = model.transform_feature(data, feat, MY_TARGET)\n",
    "        \n",
    "        # concatenate transformed individual feature to umbrella feature\n",
    "        if X == []:\n",
    "            X = X_new\n",
    "        else:\n",
    "            X = np.concatenate([X, X_new], axis=1)\n",
    "    \n",
    "    # average over all splits \n",
    "    for s in splits:\n",
    "        \n",
    "        # split data into train test set\n",
    "        X_train, X_test, Y_train, Y_test = model.split_data(X, Y_original, MY_TARGET, MY_TEST_SIZE_UMB, s)\n",
    "        \n",
    "        # feature selection with ElasticNet on train set \n",
    "        X_train, X_test, Y_train, Y_test = model.feature_selection(X_train, X_test, Y_train, Y_test, 'median')\n",
    "        \n",
    "        # predict on test set \n",
    "        results = model.predict(X_train, X_test, Y_train, Y_test, MY_MODEL_UMB, MY_PARAMS_UMB, MY_CROSS_VAL)\n",
    "        \n",
    "        print(results)\n",
    "        \n",
    "        # add to r, p totals\n",
    "        total_r.append(results['r'])\n",
    "        total_p.append(results['p'])\n",
    "        total_score.append(results['r2'])\n",
    "    \n",
    "    # add feature results to results dataframe \n",
    "    f_results = model.create_results(feature_name, na_count, total_r, total_p, total_score)\n",
    "    umbrella_results_df = umbrella_results_df.append(f_results, ignore_index = True)\n",
    "            \n",
    "    r_dict[feature_name] = total_r\n",
    "    p_dict[feature_name] = total_p\n",
    "    score_dict[feature_name] = total_score\n",
    "\n",
    "# create and show plots\n",
    "plot, chart = model.create_plotly_individual(umbrella_results_df, MY_TARGET, \n",
    "                                             DATAFRAME_TYPE, MY_MODEL_UMB, MY_TITLE_UMB)\n",
    "chart.show()\n",
    "\n",
    "# save results and plots \n",
    "model.save_results(RESULTS_FOLDER_UMBRELLA, MY_TITLE_UMB.lower(), umbrella_results_df, \n",
    "             plot, chart, state_dict_umbrella)\n",
    "plot.umbrella_plot(umbrella_results_df, PLOT_FOLDER_NAME, MY_MODEL_UMB)\n",
    "\n",
    "general.set_background('#fff9e9')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003b5d70",
   "metadata": {},
   "source": [
    "# 4. Combined Features (Individual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7db42c",
   "metadata": {},
   "source": [
    "While individual features hold some predictive power over CRT score, combining features can improve prediction accuracy. By combining features, we create the best model for CRT score prediction given the current dataset. The following protocol is used to combine individual features:\n",
    "1. Predict CRT score using all features.\n",
    "2. Remove the individual feature with the highest median $p$ value across splits.\n",
    "3. Repeat Steps 1 and 2, removing one feature at a time, until one feature remains (i.e. feature with the lowest median $p$ value).\n",
    "\n",
    "Umbrella features are also combined using a similar protocol as above, but we remove the umbrella feature with the highest median $p$ value with each iteration. \n",
    "\n",
    "*Variable and path definitions are similar to that of individual features prediction in Section 2.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8084ccc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#efe1e1';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: set variables and paths\n",
    "MY_MODEL_COMB_INDV = 'lasso'\n",
    "MY_PARAMS_COMB_INDV = {'model__alpha': np.logspace(-5, 5, 100), 'poly__degree': [1]} # structure for ridge/lasso \n",
    "# MY_PARAMS_COMB_INDV = {\n",
    "#              'model__max_depth': [10], # default is [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None]\n",
    "#              'model__min_samples_leaf': [40], # default is [20, 40, 60]\n",
    "#              'model__min_samples_split': [10], # default is [2, 5, 10]\n",
    "#              'model__n_estimators': [600], # default is [200, 400, 600, 800, 1000]\n",
    "#              'model__max_features': ['log2'],\n",
    "#              'poly__degree': [1] # default is [1]\n",
    "#         } # structure for random forests\n",
    "MY_SPLITS_COMB_INDV = range(0, 50)\n",
    "MY_MINDF_COMB_INDV = 10\n",
    "MY_MAXDF_COMB_INDV = 0.99\n",
    "MY_TEST_SIZE_COMB_INDV = 0.1\n",
    "MY_N_COMPONENTS_COMB_INDV = 50\n",
    "MY_TITLE_COMB_INDV = 'Combined Individual Features'\n",
    "\n",
    "RESULTS_FOLDER_COMBINED_INDV = ROOT_DIR + RESULTS_FOLDER_NAME + 'combined_individual_{}/'.format(MY_MODEL_COMB_INDV)\n",
    "\n",
    "general.set_background('#efe1e1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd9488fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#fff9e9';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run this cell to generate the ordering of individual features to combine\n",
    "\n",
    "to_combine = individual_results_df.sort_values('p_median', ascending=True)['feature'].values\n",
    "to_combine = to_combine.tolist()\n",
    "\n",
    "general.set_background('#fff9e9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "477270d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#fff9e9';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run this cell to store results\n",
    "state_dict_combined_individual = {\n",
    "    'model': MY_MODEL_COMB_INDV, \n",
    "    'params': MY_PARAMS_COMB_INDV, \n",
    "    'splits': MY_SPLITS_COMB_INDV,\n",
    "    'mindf': MY_MINDF_COMB_INDV,\n",
    "    'maxdf': MY_MAXDF_COMB_INDV,\n",
    "    'test_size': MY_TEST_SIZE_COMB_INDV,\n",
    "    'n_components': MY_N_COMPONENTS_COMB_INDV,\n",
    "}\n",
    "\n",
    "r_dict = {}\n",
    "p_dict = {}\n",
    "score_dict = {}\n",
    "combined_individual_results_df = pd.DataFrame({})\n",
    "\n",
    "general.set_background('#fff9e9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ff67a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to combine individual features \n",
    "\n",
    "for i in range(len(to_combine)):\n",
    "    \n",
    "    # determine splits \n",
    "    splits = model.get_splits(MY_SPLITS_COMB_INDV)\n",
    "        \n",
    "    # remove umbrella with highest median p value \n",
    "    if i != 0:\n",
    "        to_combine.pop()\n",
    "        \n",
    "    # generate combined feature name\n",
    "    combined_name = \" \".join(to_combine)\n",
    "    print(combined_name)\n",
    "        \n",
    "    X = []\n",
    "    for feat in to_combine:\n",
    "        if feat in MY_TEXT_FEATURES:\n",
    "            X_new, Y_new, na_count = model.transform_feature(data, feat, MY_TARGET, my_max_df=MY_MAXDF_COMB_INDV, \n",
    "                                                             my_min_df=MY_MINDF_COMB_INDV, my_n_components=MY_N_COMPONENTS_COMB_INDV)\n",
    "        else:\n",
    "            X_new, Y_new, na_count = model.transform_feature(data, feat, MY_TARGET)\n",
    "        \n",
    "        # concatenate transformed individual feature to all features for prediction\n",
    "        if X == []:\n",
    "            X = X_new\n",
    "        else:\n",
    "            X = np.concatenate([X, X_new], axis=1)\n",
    "    \n",
    "    # set r, p, score sums to 0\n",
    "    total_r = []\n",
    "    total_p = []\n",
    "    total_score = []\n",
    "        \n",
    "    for s in splits: \n",
    "        # split data into train test set (same split)\n",
    "        X_train, X_test, Y_train, Y_test = model.split_data(X, data[MY_TARGET], MY_TARGET, MY_TEST_SIZE_COMB_INDV s)\n",
    "        \n",
    "        # feature selection with ElasticNet on train set \n",
    "        X_train, X_test, Y_train, Y_test = model.feature_selection(X_train, X_test, Y_train, Y_test, 'median')\n",
    "        \n",
    "        # predict on test set \n",
    "        results = model.predict(X_train, X_test, Y_train, Y_test, MY_MODEL_COMB_INDV, MY_PARAMS_COMB_INDV, MY_CROSS_VAL)\n",
    "        print(results)\n",
    "        \n",
    "        # add to r, p totals\n",
    "        total_r.append(results['r'])\n",
    "        total_p.append(results['p'])\n",
    "        total_score.append(results['r2'])\n",
    "    \n",
    "    # add individual feature results to results dataframe\n",
    "    f_results = model.create_results(combined_name, na_count, total_r, total_p, total_score)\n",
    "    combined_individual_results_df = combined_individual_results_df.append(f_results, ignore_index = True)\n",
    "                \n",
    "    r_dict[combined_name] = total_r\n",
    "    p_dict[combined_name] = total_p\n",
    "    score_dict[combined_name] = total_score\n",
    "    \n",
    "# create and show plots\n",
    "plot, chart = model.create_plotly_individual(combined_individual_results_df, MY_TARGET, \n",
    "                                             DATAFRAME_TYPE, MY_MODEL_COMB_INDV, MY_TITLE_COMB_INDV)\n",
    "chart.show()\n",
    "\n",
    "# save results and plots \n",
    "model.save_results(RESULTS_FOLDER_COMBINED_INDV, MY_TITLE_COMB_INDV.lower(), combined_individual_results_df, \n",
    "             plot, chart, state_dict_combined_individual)\n",
    "plot.combined_plot(combined_individual_results_df, PLOT_FOLDER_NAME, 'individual')\n",
    "\n",
    "general.set_background('#fff9e9')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742c2c0b",
   "metadata": {},
   "source": [
    "# 5. Combined Features (Umbrella) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b34510",
   "metadata": {},
   "source": [
    "In this section, we combine umbrella features using a similar protocol to combined individual prediction in Section 4.\n",
    "\n",
    "*Variable and path definitions are similar to that of individual features prediction in Section 2.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78db4001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#efe1e1';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: set variables and paths\n",
    "MY_MODEL_COMB_UMB = 'rfr'\n",
    "# MY_PARAMS_COMB_UMB = {'model__alpha': np.logspace(-5, 5, 100), \n",
    "#                       'poly__degree': [2], 'model__tol': [0.01]} # structure for ridge/lasso\n",
    "MY_PARAMS_COMB_UMB = {\n",
    "             'model__max_depth': [10], # default is [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None]\n",
    "             'model__min_samples_leaf': [20], # default is [20, 40, 60]\n",
    "             'model__min_samples_split': [10], # default is [2, 5, 10]\n",
    "             'model__n_estimators': [600], # default is [200, 400, 600, 800, 1000]\n",
    "             'model__max_features': ['log2'],\n",
    "             'poly__degree': [1] # default is [1]\n",
    "        } # structure for random forests\n",
    "\n",
    "MY_SPLITS_COMB_UMB = range(0, 50)\n",
    "MY_MINDF_COMB_UMB = 10\n",
    "MY_MAXDF_COMB_UMB = 0.99\n",
    "MY_TEST_SIZE_COMB_UMB = 0.1\n",
    "MY_N_COMPONENTS_COMB_UMB = 50\n",
    "MY_TITLE_COMB_UMB = 'Combined Umbrella Features'\n",
    "\n",
    "RESULTS_FOLDER_COMBINED_UMBRELLA = ROOT_DIR + RESULTS_FOLDER_NAME + 'combined_umbrella_{}/'.format(MY_MODEL_COMB_UMB)\n",
    "\n",
    "general.set_background('#efe1e1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15e2e77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#fff9e9';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run this cell to store results\n",
    "state_dict_combined_umbrella = {\n",
    "    'model': MY_MODEL_COMB_UMB, \n",
    "    'params': MY_PARAMS_COMB_UMB, \n",
    "    'splits': MY_SPLITS_COMB_UMB,\n",
    "    'mindf': MY_MINDF_COMB_UMB,\n",
    "    'maxdf': MY_MAXDF_COMB_UMB,\n",
    "    'test_size': MY_TEST_SIZE_COMB_UMB,\n",
    "    'n_components': MY_N_COMPONENTS_COMB_UMB,\n",
    "}\n",
    "\n",
    "r_dict = {}\n",
    "p_dict = {}\n",
    "score_dict = {}\n",
    "combined_umbrella_results_df = pd.DataFrame({})\n",
    "\n",
    "general.set_background('#fff9e9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf6c6f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#fff9e9';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run this cell to generate the ordering of umbrella features to combine\n",
    "\n",
    "to_combine = umbrella_results_df.sort_values('p_median', ascending=True)['feature'].values\n",
    "\n",
    "# remove combinations of umbrella features\n",
    "for elem in to_combine:\n",
    "    if elem.startswith('all'):\n",
    "        to_combine = np.delete(to_combine, np.where(to_combine == elem))\n",
    "\n",
    "general.set_background('#fff9e9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3b6b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to combine umbrella features \n",
    "\n",
    "for i in range(len(to_combine)):\n",
    "        \n",
    "    # remove umbrella with highest median p value \n",
    "    if i != 0:\n",
    "        to_combine.pop()\n",
    "\n",
    "    # generate combined feature name\n",
    "    combined_name = \" \".join(to_combine)\n",
    "    print(combined_name)\n",
    "    \n",
    "    # determine splits \n",
    "    splits = model.get_splits(MY_SPLITS_COMB_UMB)\n",
    "    \n",
    "    # get all individual features \n",
    "    all_feats = []\n",
    "    for umbrella_feat in to_combine:\n",
    "        for feat in combined_feats_dict[umbrella_feat]:\n",
    "            all_feats.append(feat)\n",
    "    \n",
    "    X = []\n",
    "    for feat in all_feats:\n",
    "        if feat in MY_TEXT_FEATURES:\n",
    "            X_new, Y_new, na_count = model.transform_feature(data, feat, MY_TARGET, my_max_df=MY_MAXDF_COMB_UMB, \n",
    "                                                             my_min_df=MY_MINDF_COMB_UMB, \n",
    "                                     my_n_components=MY_N_COMPONENTS_COMB_UMB)\n",
    "        else:\n",
    "            X_new, Y_new, na_count = model.transform_feature(data, feat, MY_TARGET)\n",
    "        \n",
    "        # concatenate transformed individual feature\n",
    "        if X == []:\n",
    "            X = X_new\n",
    "        else:\n",
    "            X = np.concatenate([X, X_new], axis=1)\n",
    "    \n",
    "    # set r, p, score sums to 0\n",
    "    total_r = []\n",
    "    total_p = []\n",
    "    total_score = []\n",
    "        \n",
    "    for s in splits: \n",
    "        # split data into train test set (same split)\n",
    "        X_train, X_test, Y_train, Y_test = model.split_data(X, data[MY_TARGET], MY_TARGET, MY_TEST_SIZE_COMB_UMB, s)\n",
    "        \n",
    "        # feature selection with ElasticNet on train set \n",
    "        X_train, X_test, Y_train, Y_test = model.feature_selection(X_train, X_test, Y_train, Y_test, 'median')\n",
    "        \n",
    "        # predict on test set \n",
    "        results = model.predict(X_train, X_test, Y_train, Y_test, MY_MODEL_COMB_UMB, MY_PARAMS_COMB_UMB, MY_CROSS_VAL)\n",
    "        print(results)\n",
    "        \n",
    "        # add to r, p totals\n",
    "        total_r.append(results['r'])\n",
    "        total_p.append(results['p'])\n",
    "        total_score.append(results['r2'])\n",
    "    \n",
    "    # add individual feature results to results dataframe\n",
    "    f_results = model.create_results(combined_name, na_count, total_r, total_p, total_score)\n",
    "    combined_umbrella_results_df = combined_umbrella_results_df.append(f_results, ignore_index = True)\n",
    "                \n",
    "    r_dict[combined_name] = total_r\n",
    "    p_dict[combined_name] = total_p\n",
    "    score_dict[combined_name] = total_score\n",
    "    \n",
    "# create and show plots\n",
    "plot, chart = model.create_plotly_individual(combined_umbrella_results_df, MY_TARGET, \n",
    "                                             DATAFRAME_TYPE, MY_MODEL_COMB_UMB, MY_TITLE_COMB_UMB)\n",
    "chart.show()\n",
    "\n",
    "# save results and plots \n",
    "model.save_results(RESULTS_FOLDER_COMBINED_UMBRELLA, MY_TITLE_COMB_UMB.lower(), combined_umbrella_results_df, \n",
    "             plot, chart, state_dict_combined_umbrella)\n",
    "plot.combined_plot(combined_umbrella_results_df, PLOT_FOLDER_NAME, 'umbrella')\n",
    "\n",
    "general.set_background('#fff9e9')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378b5c60",
   "metadata": {},
   "source": [
    "# 6: Informative Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a19a283",
   "metadata": {},
   "source": [
    "This is a separate module from the above pipeline. In this module, we generate the most informative words and phrases for domains, mentions, hashtags, followees, text (Tweets and Retweets), bios, follower bios, and followee bios. The most informative features are those that yield the largest and smallest coefficients after TF-IDF feature extraction and Ridge regression with cross-validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6349cc",
   "metadata": {},
   "source": [
    "<font color='green'>**Variable Descriptions**</font>\n",
    "1. **FEAT_INFORMATIVE** (string): name of target feature, as it appears in dataframe \n",
    "2. **N_INFORMATIVE** (integer): top N_IF and bottom N_IF informative features displayed, default is 20 \n",
    "3. **MAXDF_INFORMATIVE** (float): max_df parameter for TF-IDF, default is 1.0 ([*TF-IDF specs*](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html))\n",
    "4. **MINDF_INFORMATIVE** (integer): max_df parameter for TF-IDF, default is 10\n",
    "5. **NGRAM_INFORMATIVE** ((integer, integer)): n_gram range parameter for TF-IDF, default is (1, 1)\n",
    "6. **STATE_INFORMATIVE** (integer): random state for train/test split\n",
    "\n",
    "<font color='blue'>**Path Descriptions**</font>\n",
    "1. **RESULTS_FOLDER_INFORMATIVE** (string): name of folder to save informative feature results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4843e90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#efe1e1';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: set variables \n",
    "FEAT_INFORMATIVE = 'followees'\n",
    "N_INFORMATIVE = 15\n",
    "MAXDF_INFORMATIVE = 0.99\n",
    "MINDF_INFORMATIVE = 10 \n",
    "NGRAM_INFORMATIVE = (1, 1) \n",
    "STATE_INFORMATIVE = 17 \n",
    "\n",
    "RESULTS_FOLDER_INFORMATIVE = ROOT_DIR + RESULTS_FOLDER_NAME + 'informative_features/{}/'.format(FEAT_INFORMATIVE)\n",
    "\n",
    "general.set_background('#efe1e1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "794aecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to generate most informative features\n",
    "r, p, score, chart = model.get_informative_features(data, FEAT_INFORMATIVE, MY_TARGET, RESULTS_FOLDER_INFORMATIVE, \n",
    "                                                   n=N_INFORMATIVE, maxDF=MAXDF_INFORMATIVE, minDF=MINDF_INFORMATIVE, \n",
    "                                                   n_gram=NGRAM_INFORMATIVE, my_state=STATE_INFORMATIVE)\n",
    "\n",
    "chart.show()\n",
    "\n",
    "general.set_background('#fff9e9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea602eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
