{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eaab35b",
   "metadata": {},
   "source": [
    "# This file contains all the functions relevant for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2f3b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import statistics\n",
    "import copy\n",
    "import math\n",
    "import re\n",
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# model functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# plot functions\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0de927",
   "metadata": {},
   "source": [
    "# Split Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21488263",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function generates a list of splits for the pipeline.\n",
    "\n",
    "Inputs:\n",
    "my_splits (list or integer): list of splits or number of random splits \n",
    "\n",
    "Outputs:\n",
    "splits (list): list of integers representing splits for pipeline\n",
    "\"\"\"\n",
    "def get_splits(my_splits):\n",
    "    if type(my_splits) == int:\n",
    "        splits = []\n",
    "        for i in range(my_splits):\n",
    "            n = random.randint(0, 999999)\n",
    "            splits.append(n)\n",
    "    else:\n",
    "        splits = my_splits\n",
    "    \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "99a3dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function splits the data into a train and test set. \n",
    "\n",
    "Inputs:\n",
    "X (array): features  \n",
    "Y (array): target variable \n",
    "target (string): name of target variable \n",
    "my_split (float): size of test set out of 1.0\n",
    "my_state (integer): random state for split\n",
    "\n",
    "Ouputs:\n",
    "X_train (array): train set of features\n",
    "X_test (array): test set of features\n",
    "Y_train (array): train set of target \n",
    "Y_test (array): test set of target\n",
    "\"\"\"\n",
    "\n",
    "def split_data(X, Y, target, my_split, my_state):\n",
    "    \n",
    "    # stratify CRT scores \n",
    "    bin_count = 0\n",
    "    for i in Y.value_counts() > 1:\n",
    "        if i:\n",
    "            bin_count += 1      \n",
    "    bin_count -= 1\n",
    "\n",
    "    bins = np.linspace(0, 1, bin_count)\n",
    "    y_binned = np.digitize(Y, bins)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test  = train_test_split(X,Y, test_size=my_split, stratify=y_binned, \n",
    "                                                         random_state=my_state)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63781645",
   "metadata": {},
   "source": [
    "# Transform Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "id": "46da37e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function transforms features by performing feature extraction and\n",
    "dimensionality reduction on text features and log transformation (if applicable) and standardization on\n",
    "quantitative features.\n",
    "\n",
    "Inputs:\n",
    "df (pandas dataframe): dataframe containing features \n",
    "feature (string): name of feature to be transformed\n",
    "target (string): name of target variable (CRT score)\n",
    "my_min_df (integer): TF-IDF min_df parameter \n",
    "my_n_components (integer): TruncatedSVD n_components parameter\n",
    "\n",
    "Outputs:\n",
    "X (array): transformed feature \n",
    "Y (array): target variable \n",
    "na_count (float): number of NaN values for feature  \n",
    "\"\"\"\n",
    "def transform_feature(df, feature, target, my_max_df=None, my_min_df=None, my_n_components=None):\n",
    "    \n",
    "    na_count = df[feature].isna().sum()\n",
    "    df = df.dropna(subset=[feature])\n",
    "    \n",
    "    scale = StandardScaler()\n",
    "    \n",
    "    if feat in ['text', 'bio', 'follower_bios', 'followee_bios']:\n",
    "        my_binary = False\n",
    "    else:\n",
    "        my_binary = True\n",
    "    if feat == 'bio':\n",
    "        my_min_df = 5\n",
    "\n",
    "    if df[feature].dtype in [float, int, np.float64, np.int64]:\n",
    "\n",
    "        skew = df[feature].skew(axis=0) # check if high or medium skew \n",
    "\n",
    "        if -0.5 > skew or 0.5 < skew:\n",
    "            constant = abs(df[feature].min()) + 0.001\n",
    "            X_ = df[feature].apply(lambda x: np.log(x + constant)).to_numpy()\n",
    "\n",
    "        else:\n",
    "            X_ = df[feature].to_numpy()\n",
    "\n",
    "        X = scale.fit_transform(X_.reshape(-1,1))\n",
    "\n",
    "    else:\n",
    "        if feature in ['text', 'followee_bios', 'follower_bios']:\n",
    "            my_token_pattern=r'(?ui)\\b\\w[a-z]\\w[a-z]+\\b'\n",
    "        else:\n",
    "            my_token_pattern=r'(?u)\\b\\w\\w+\\b'\n",
    "            \n",
    "        tfidf = TfidfVectorizer(ngram_range=(1,1),max_df= my_max_df,min_df = my_min_df,binary=my_binary, token_pattern=my_token_pattern)\n",
    "        svd = TruncatedSVD(n_components=my_n_components, random_state=17)\n",
    "        X = scale.fit_transform(svd.fit_transform(tfidf.fit_transform(df[feature])))\n",
    "\n",
    "    Y = df[target]\n",
    "\n",
    "    return X, Y, na_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ad9175",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a2b677e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function performs feature selection using ElasticNetCV.\n",
    "\n",
    "Inputs:\n",
    "X_train (array): train set of features\n",
    "X_test (array): test set of features\n",
    "Y_train (array): train set of target \n",
    "Y_test (array): test set of target\n",
    "\n",
    "Outputs:\n",
    "X_train (array): train set of features after feature selection\n",
    "X_test (array): test set of features after feature selection\n",
    "Y_train (array): train set of target after feature selection\n",
    "Y_test (array): test set of target after feature selection\n",
    "\"\"\"\n",
    "\n",
    "def feature_selection(X_train, X_test, Y_train, Y_test, thresh):\n",
    "    sfm_selector = SelectFromModel(estimator=ElasticNetCV(), threshold=thresh)\n",
    "    sfm_selector.fit(X_train, Y_train)\n",
    "\n",
    "    X_train_df = pd.DataFrame(X_train)\n",
    "    X_test_df = pd.DataFrame(X_test)\n",
    "\n",
    "    X_train = X_train_df[X_train_df.columns[sfm_selector.get_support()]].to_numpy()\n",
    "    X_test = X_test_df[X_train_df.columns[sfm_selector.get_support()]].to_numpy()\n",
    "\n",
    "    return (X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f0a340",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "id": "0aff253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function fits a model to training data with cross-validation and predicts CRT score using the model. \n",
    "\n",
    "Inputs: \n",
    "X_train (array): train set of features\n",
    "X_test (array): test set of features\n",
    "Y_train (array): train set of target \n",
    "Y_test (array): test set of target\n",
    "my_model (string): name of model \n",
    "my_params (dictionary): dictionary of pipeline parameters \n",
    "\n",
    "Outputs:\n",
    "results (dictionary): dictionary of results, containing best r value, p value, and R^2 score from GridSearch\n",
    "\"\"\"\n",
    "def predict(X_train, X_test, Y_train, Y_test, my_model, my_params, my_cross_val):\n",
    "    \n",
    "    models = {'ridge': Ridge(random_state= 17), \n",
    "                'lasso': Lasso(random_state= 17), \n",
    "                'rfr': RandomForestRegressor(random_state= 17)}\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=1)),\n",
    "        ('model', models[my_model]),\n",
    "    ])\n",
    "\n",
    "    grid = GridSearchCV(pipe, param_grid=my_params, cv=my_cross_val, n_jobs=-1, verbose=0, scoring='r2')\n",
    "    grid.fit(X_train, Y_train)\n",
    "\n",
    "    y_pred = grid.predict(X_test)\n",
    "    y_pred=np.maximum(0,np.minimum(y_pred, 1))\n",
    "    \n",
    "    r, p = pearsonr(Y_test, y_pred) \n",
    "    \n",
    "    results = {\"r\": abs(r), \"p\": p, \"r2\": grid.best_score_}\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f300c05e",
   "metadata": {},
   "source": [
    "# Create and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82048176",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function generates statistics from the results.\n",
    "\n",
    "Inputs: \n",
    "feat (string): feature name\n",
    "na_count (integer): number of dropped users\n",
    "total_r (list): list of r values from prediction\n",
    "total_p (list): list of p values from prediction\n",
    "total_score (list): list of R^2 scores from prediction\n",
    "\n",
    "Outputs:\n",
    "f_results (dictionary): dictionary of statistics of results (mean, median, range)\n",
    "\"\"\"\n",
    "def create_results(feat, na_count, total_r, total_p, total_score):\n",
    "\n",
    "    f_results = {}\n",
    "    f_results['r_mean'] = statistics.mean(total_r)\n",
    "    f_results['p_mean'] = statistics.mean(total_p)\n",
    "    f_results['feature'] = feat\n",
    "    f_results['na_count'] = na_count\n",
    "    f_results['r2_mean'] = statistics.mean(total_score)\n",
    "    f_results['r2_median'] = statistics.median(total_score)\n",
    "    f_results['r_median'] = statistics.median(total_r)\n",
    "    f_results['p_median'] = statistics.median(total_p)\n",
    "    f_results['r2_range'] = [min(total_score), max(total_score)]\n",
    "    f_results['r_range'] = [min(total_r), max(total_r)]\n",
    "    f_results['p_range'] = [min(total_p), max(total_p)]\n",
    "    f_results['r_history'] = total_r\n",
    "    f_results['p_history'] = total_p\n",
    "    f_results['score_history'] = total_score\n",
    "    \n",
    "    return f_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdb1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function saves the results to the appropriate folder.\n",
    "\n",
    "Inputs:\n",
    "results_folder (string): path to results folder\n",
    "results_name (string): name of results \n",
    "df (pandas dataframe): dataframe of results\n",
    "plot (plotly): plot of results\n",
    "chart (plotly): chart of results\n",
    "states (dictionary): dictionary of parameters\n",
    "\n",
    "Outputs:\n",
    "None\n",
    "\"\"\"\n",
    "\n",
    "def save_results(results_folder, results_name, df, plot, chart, states):\n",
    "    results_name = results_name.replace(\" \", \"_\")\n",
    "    # save results and plots \n",
    "    isExist = os.path.exists(results_folder)\n",
    "    if not isExist:\n",
    "        os.makedirs(results_folder)  \n",
    "    df.to_pickle(results_folder + '{}_df.pickle'.format(results_name))\n",
    "    plot.write_html(results_folder + \"{}_plot.html\".format(results_name))\n",
    "    chart.write_html(results_folder + \"{}_chart.html\".format(results_name))\n",
    "\n",
    "    # save states\n",
    "    with open(results_folder + '{}.txt'.format(results_name), 'w') as f:\n",
    "         print(states, file=f)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1af3a2",
   "metadata": {},
   "source": [
    "# Combine Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "id": "c598fe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function combines individual features to create the best model.\n",
    "\n",
    "Inputs:\n",
    "feature_dict (dictionary): dictionary mapping feature name to list of train and test data after feature selection\n",
    "individual_df (pandas dataframe): results from individual features run, ranking features from most predictive to least predictive \n",
    "target (string): name of target variable (CRT score)\n",
    "my_model (string): name of model \n",
    "my_params (dictionary): dictionary of pipeline parameters \n",
    "\n",
    "Outputs:\n",
    "combined_results_df (pandas dataframe): dataframe displaying feature combinations and respective r values, p values and R^2 scores\n",
    "\"\"\"\n",
    "\n",
    "def combine_features(feature_dict, individual_df, target, my_model, my_params):\n",
    "    individual_df = individual_df.sort_values('r', ascending=False, ignore_index=True)\n",
    "    combined_results_df = pd.DataFrame({})\n",
    "    features = []\n",
    "    \n",
    "    X_train = np.array([])\n",
    "    X_test = np.array([])\n",
    "    Y_train = np.array([])\n",
    "    Y_test = np.array([])\n",
    "    \n",
    "    for i, row in individual_df.iterrows():\n",
    "        \n",
    "        feature = row['feature']\n",
    "        features.append(feature)\n",
    "                \n",
    "        if i != 0:\n",
    "            X_train_i, X_test_i, Y_train_i, Y_test_i = feature_dict[feature]\n",
    "        \n",
    "            # concat new feature with old features \n",
    "            X_train = np.hstack([X_train, X_train_i])\n",
    "            X_test = np.hstack([X_test, X_test_i])\n",
    "            \n",
    "        else:\n",
    "            X_train, X_test, Y_train, Y_test = feature_dict[feature]\n",
    "                \n",
    "        results = predict(X_train, X_test, Y_train, Y_test, my_model, my_params, 10)\n",
    "        \n",
    "        f_results = {\n",
    "            'features': copy.deepcopy(features),\n",
    "            'r': results['r'],\n",
    "            'p': results['p'],\n",
    "            'r2': results['r2']\n",
    "        }\n",
    "        \n",
    "        combined_results_df = combined_results_df.append(f_results, ignore_index = True)\n",
    "    \n",
    "    combined_results_df = combined_results_df.sort_values('r', ascending=False, ignore_index=True)\n",
    "    \n",
    "    return combined_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa69dd91",
   "metadata": {},
   "source": [
    "# Informative Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "93a3ae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function performs feature extraction using TF-IDF, runs Ridge with cross-validation, and prints most informative features.\n",
    "\n",
    "Inputs:\n",
    "data (pandas dataframe): dataframe containing features \n",
    "feat (string): name of feature\n",
    "target (string): name of target variable (CRT score)\n",
    "results_folder (string): path to informative features results folder\n",
    "n (integer): number of top features to show\n",
    "maxDF (float): TF-IDF max_df parameter\n",
    "minDF (float): TF-IDF min_df parameter\n",
    "n_gram ((integer, integer)): TF-IDF n_gram range parameter \n",
    "my_state (integer): random state for train/test split\n",
    "\n",
    "Outputs\n",
    "r (float): Pearson r correlation coefficient after Ridge and cross-validation\n",
    "p (float): p value after Ridge and cross-validation\n",
    "score (float): best R^2 score from GridSearchCV\n",
    "chart (plotly): chart displaying informative features and their coefficients \n",
    "\"\"\"\n",
    "def get_informative_features(data, feat, target, results_folder, n=10, maxDF=1.0, minDF=10, n_gram=(1,1), my_state=17):\n",
    "    \n",
    "    # create coefficient dictionary \n",
    "    coefs_dict = {\n",
    "        'high_coefs': [],\n",
    "        'high_names': [],\n",
    "        'low_coefs': [],\n",
    "        'low_names': []\n",
    "    }\n",
    "    \n",
    "    if feat == 'text':\n",
    "        vectorizer = TfidfVectorizer(ngram_range=n_gram, max_df= maxDF, min_df=minDF, use_idf=True,binary=False, analyzer='word', token_pattern=r'(?ui)\\b\\w[a-z]\\w[a-z]\\w[a-z]+\\b')\n",
    "    elif feat == \"followees\": \n",
    "        vectorizer = TfidfVectorizer(ngram_range=n_gram,max_df= maxDF,min_df = minDF,use_idf=True,binary=True)\n",
    "    elif feat == 'domains': \n",
    "        vectorizer = TfidfVectorizer(ngram_range=n_gram,max_df= maxDF,min_df = minDF,use_idf=True,binary=True)\n",
    "    elif feat == 'hashtags': \n",
    "        vectorizer = TfidfVectorizer(ngram_range=n_gram,max_df= maxDF,min_df = minDF,use_idf=True,binary=True)\n",
    "    elif feat == 'mentions': \n",
    "        vectorizer = TfidfVectorizer(ngram_range=n_gram,max_df=maxDF,min_df = minDF,use_idf=True,binary=True)\n",
    "    elif feat in ['bio', 'follower_bios', 'followee_bios']:\n",
    "        vectorizer = TfidfVectorizer(ngram_range=n_gram,max_df=maxDF,min_df = minDF,use_idf=True,binary=False, analyzer='word', token_pattern=r'(?ui)\\b\\w[a-z]\\w[a-z]+\\b')\n",
    "    \n",
    "    params = {'alpha': np.logspace(-5, 5, 100)}\n",
    "    \n",
    "    data = data[data[feat].notnull()]\n",
    "    X_text = vectorizer.fit_transform(data[feat]) \n",
    "    Y = data[target]\n",
    "    \n",
    "    bins = np.linspace(0, 1, 7)\n",
    "    y_binned = np.digitize(Y, bins)\n",
    "    \n",
    "    # run Ridge regression + cross-validation\n",
    "    X_train, X_test, Y_train, Y_test  = train_test_split(X_text, Y, test_size=0.1, stratify=y_binned, random_state=my_state)\n",
    "\n",
    "    grid = GridSearchCV(Ridge(random_state=17), param_grid=params, cv=5, n_jobs=-1, verbose=0, scoring='r2')\n",
    "    grid.fit(X_train, Y_train)\n",
    "    y_pred = grid.predict(X_test)\n",
    "    y_pred=np.maximum(0, np.minimum(y_pred, 1))\n",
    "\n",
    "    coefs_with_fns = sorted(zip(grid.best_estimator_.coef_, vectorizer.get_feature_names_out()))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        coefs_dict['low_coefs'].append(coef_1)\n",
    "        coefs_dict['low_names'].append(fn_1)\n",
    "        coefs_dict['high_coefs'].append(coef_2)\n",
    "        coefs_dict['high_names'].append(fn_2)\n",
    "\n",
    "    r, p = (pearsonr(Y_test, y_pred))\n",
    "    score = grid.best_score_\n",
    "\n",
    "    chart = create_plotly_informative(coefs_dict, feat, target, r, p, minDF, maxDF, n_gram)\n",
    "        \n",
    "    isExist = os.path.exists(results_folder)\n",
    "    if not isExist:\n",
    "        os.makedirs(results_folder)\n",
    "        \n",
    "    chart.write_html(results_folder + \"{}_{}.html\".format(feat, n_gram))\n",
    "    \n",
    "    return (r, p, score, chart)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b79f77",
   "metadata": {},
   "source": [
    "# Create Plotly Charts and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "cfc8f0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function generates a plotly plot and chart for individual feature results.\n",
    "\n",
    "Inputs:\n",
    "df (pandas dataframe): dataframe with individual feature results\n",
    "target (string): name of target variable \n",
    "dataframe_type (string): dropped, imputed, or full \n",
    "my_model (string): name of model \n",
    "\n",
    "Outputs: \n",
    "fig (plotly): plot displaying individual feature results\n",
    "chart (plotly): chart displaying individual feature results\n",
    "\"\"\"\n",
    "def create_plotly_individual(df, target, dataframe_type, my_model, title):\n",
    "    \n",
    "    textfeat = ['mentions', 'text', 'domains', 'bio', 'followees', 'follower_bios', 'followee_bios',\n",
    "           'hashtags']\n",
    "    \n",
    "    # create plot\n",
    "    df = df.dropna(subset=['r_median'])\n",
    "    df_plot = df.sort_values(by=[\"r_median\"], ascending=True)\n",
    "    df_plot_reverse = df.sort_values(by=[\"r_median\"], ascending=False)\n",
    "    \n",
    "    fig = go.Figure(go.Bar(\n",
    "                y=df_plot['feature'],\n",
    "                x=df_plot['r_median'],\n",
    "                orientation='h',\n",
    "                text=df_plot['r_median'].apply(lambda x: \"{:.2f}\".format(x)),\n",
    "                textposition='auto',\n",
    "                marker_color=['cornflowerblue' if col in textfeat else 'lightslategray' for col in df_plot['feature']]\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        yaxis_title=\"Feature Name\",\n",
    "        xaxis_title=\"R Median\",\n",
    "        font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            size=10,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "        tickmode='linear'),\n",
    "\n",
    "        width=1000, height=800,\n",
    "\n",
    "        title={\n",
    "            'text': \"{} (Target: {}; Data: {}; Model: {})\".format(title, target, dataframe_type, my_model),\n",
    "            'y':.92,\n",
    "            'x':0.5,\n",
    "            'font': dict(\n",
    "                size=22,\n",
    "            ),\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'}\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(title_font_size=15)\n",
    "    fig.update_xaxes(title_font_size=15)\n",
    "\n",
    "    fig.update_traces(textposition='outside', textfont_size=10)\n",
    "    \n",
    "    # create chart\n",
    "    chart = go.Figure(data=[go.Table(\n",
    "    header=dict(values=['Feature Name', 'R Median', 'P Median', 'R^2 Median', 'Dropped Count'],\n",
    "                fill_color='cornflowerblue',\n",
    "                align='left'),\n",
    "    cells=dict(values=[df_plot_reverse.feature, \n",
    "                       df_plot_reverse.r_median.apply(lambda x: \"{:.5f}\".format(x)),\n",
    "                      df_plot_reverse.p_median.apply(lambda x: \"{:.5f}\".format(x)), \n",
    "                       df_plot_reverse.r2_median.apply(lambda x: \"{:.5f}\".format(x)), \n",
    "                       df_plot_reverse.na_count],\n",
    "               fill_color='lightgray',\n",
    "               align='left'))\n",
    "    ])\n",
    "    \n",
    "    chart.update_layout(\n",
    "    title={\n",
    "            'text': \"{} (Target: {}; Data: {}; Model: {})\".format(title, target, dataframe_type, my_model),\n",
    "            'y':.89,\n",
    "            'x':0.5,\n",
    "            'font': dict(\n",
    "                size=22,\n",
    "            ),\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'},\n",
    "    font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            color=\"black\",\n",
    "            size=12\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return (fig, chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "aa157acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function generates a plotly plot and chart for combined feature results.\n",
    "\n",
    "Inputs:\n",
    "df (pandas dataframe): dataframe with combined feature results\n",
    "target (string): name of target variable \n",
    "dataframe_type (string): dropped, imputed, or full \n",
    "my_model (string): name of model \n",
    "\n",
    "Outputs: \n",
    "chart (plotly): chart displaying combined feature results\n",
    "\"\"\"\n",
    "def create_plotly_combined(df, target, dataframe_type, my_model):\n",
    "    \n",
    "    textfeat = ['mentions', 'text', 'domains', 'bio', 'followees', 'follower_bios', 'followee_bios',\n",
    "           'hashtags']\n",
    "    \n",
    "    df = df.dropna(subset=['r'])\n",
    "    df_plot_reverse = df.sort_values(by=[\"r\"], ascending=False)\n",
    "    \n",
    "    # create chart\n",
    "    chart = go.Figure(data=[go.Table(\n",
    "    header=dict(values=['Features', 'R Value', 'P Value', 'R^2'],\n",
    "                fill_color='cornflowerblue',\n",
    "                align='left'),\n",
    "    cells=dict(values=[[', '.join(x) for x in df_plot_reverse.features],\n",
    "                       df_plot_reverse.r.apply(lambda x: \"{:.5f}\".format(x)),\n",
    "                      df_plot_reverse.p.apply(lambda x: \"{:.5f}\".format(x)), \n",
    "                      df_plot_reverse.r2.apply(lambda x: \"{:.5f}\".format(x))],\n",
    "               fill_color='lightgray',\n",
    "               align='left'))\n",
    "    ])\n",
    "    \n",
    "    chart.update_layout(\n",
    "    title={\n",
    "            'text': \"Combined Features (Target: {}; Data: {}; Model: {})\".format(target, dataframe_type, my_model),\n",
    "            'y':.89,\n",
    "            'x':0.5,\n",
    "            'font': dict(\n",
    "                size=22,\n",
    "            ),\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'},\n",
    "    font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            color=\"black\",\n",
    "            size=12\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "1628653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function generates a plotly chart from informative features module.\n",
    "\n",
    "Inputs:\n",
    "coefs_dict (dictionary): contains four keys (high_coefs, high_names, low_coefs, low_names)\n",
    "feat (string): name of feature\n",
    "r (float): Pearson r correlation coefficient after Ridge and cross-validation\n",
    "p (float): p value after Ridge and cross-validation\n",
    "min_df (float): TF-IDF min_df parameter\n",
    "max_df (float): TF-IDF max_df parameter\n",
    "n_gram ((integer, integer)): TF-IDF n_gram range parameter \n",
    "\n",
    "Outputs: \n",
    "fig (plotly): chart displaying feature selection results\n",
    "\"\"\"\n",
    "def create_plotly_informative(coefs_dict, feat, target, r, p, min_df, max_df, n_gram):\n",
    "    \n",
    "    # create chart\n",
    "    chart=[go.Table(\n",
    "        header=dict(values=['Terms (Low CRT Score)', 'Coefficients',  \n",
    "                         'Terms (High CRT Score)', 'Coefficients', ],\n",
    "                fill_color='papayawhip',\n",
    "                align='left'),\n",
    "    cells=dict(values=[coefs_dict['low_names'], [\"{:.4f}\".format(x) for x in coefs_dict['low_coefs']], \n",
    "                       coefs_dict['high_names'], [\"{:.4f}\".format(x) for x in coefs_dict['high_coefs']]],\n",
    "               fill=dict(color=['lightgray', 'snow', 'lightgray', 'snow']),\n",
    "               align='left'))]\n",
    "    \n",
    "    layout = go.Layout(\n",
    "    height=700,\n",
    "    width=700,\n",
    "        \n",
    "    annotations=[\n",
    "        go.layout.Annotation(\n",
    "            showarrow=False,\n",
    "            text='min_df: {}, max_df: {}, n_gram: {}, r: {:.3f}, p value: {:.3f}'.format(min_df, max_df, n_gram, r, p),\n",
    "            xanchor='center',\n",
    "            x=.5,\n",
    "            yanchor='bottom',\n",
    "            y=1.03\n",
    "        )])\n",
    "    \n",
    "    fig = go.FigureWidget(data=chart, layout=layout)\n",
    "    \n",
    "    fig.update_layout(\n",
    "    title={\n",
    "            'text': \"Informative Features for {}\".format(feat),\n",
    "            'y':.93,\n",
    "            'x':0.5,\n",
    "            'font': dict(\n",
    "                size=17,\n",
    "            ),\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'},\n",
    "    font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            color=\"black\",\n",
    "            size=12\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
