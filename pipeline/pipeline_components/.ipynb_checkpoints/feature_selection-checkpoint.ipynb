{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22dd2798",
   "metadata": {},
   "source": [
    "# This script performs feature selection using ElasticNet model with cross-validation and the embedded method, where the features with the lowest coefficients are dropped after each pass through ElasticNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f1acbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "# feature selection packages \n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split \n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aaefa4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function performs feature selection using ElasticNetCV with cross validation \n",
    "\n",
    "Inputs:\n",
    "df (pandas df): master dataframe  \n",
    "feat (string): name of feature\n",
    "feats (list): names of target features as strings\n",
    "target (string): CRT target feature (numeric, conceptual, or both)\n",
    "params (dictionary): parameters for tuning pipeline\n",
    "history (dictionary): history of results, containing information on {r values after Ridge, p values after Ridge\n",
    "                      thresholds, number of features, selected feature names, ElasticNet best parameters,\n",
    "                      and Ridge model scores}\n",
    "stop (integer): stop feature selection when selected number of features equals this value \n",
    "count (integer): counter variable\n",
    "display (boolean): if True, print progress statements\n",
    "iters (integer): number of iterations to perform Ridge + cross validation\n",
    "\n",
    "Outputs:\n",
    "results (dictionary): results after feature selection, containing information on {feature name,\n",
    "                      best set of predictors, r value from best predictors, and full history}\n",
    "\"\"\"\n",
    "def feature_selection(df_train, df_test, feat, feats, target, params, history = None, \n",
    "                      stop=1, count=0, display=True, iters=1):\n",
    "    \n",
    "    df_train = df_train.dropna(subset=feats) # drop any rows that have NaN values \n",
    "    \n",
    "    # run initial fitting prior to any drops \n",
    "    if count == 0:\n",
    "        \n",
    "        history = {'r_vals': [], 'p_vals': [], 'thresholds': [], 'n_features': [], \n",
    "                                             'selected_feats': [], 'params': [], 'ridge_score': [],\n",
    "                  'r_vals_test': [], 'p_vals_test': []}\n",
    "        \n",
    "        if display: \n",
    "            print(\"~~~ {} ~~~\".format(feat))\n",
    "            print(\"Running initial fitting...\")\n",
    "            \n",
    "        r, p, score, r_test, p_test, score_test = compute_metrics(df_train, df_test, target, feats, iters)\n",
    "        \n",
    "        # add results to history \n",
    "        history['thresholds'].append(0)\n",
    "        history['n_features'].append(len(feats))\n",
    "        history['r_vals'].append(r)\n",
    "        history['p_vals'].append(p)\n",
    "        history['selected_feats'].append(np.array(feats))\n",
    "        history['params'].append({})\n",
    "        history['ridge_score'].append(score)\n",
    "        history['r_vals_test'].append(abs(r_test))\n",
    "        history['p_vals_test'].append(abs(p_test))\n",
    "        \n",
    "        if display: \n",
    "            print(\"r: \", round(r, 5))\n",
    "            print(\"r test: \", round(r_test, 5))\n",
    "            print(\"Total number of features: \", len(feats))\n",
    "        \n",
    "        if len(feats) <= stop:\n",
    "            if display: \n",
    "                print(\"Selection ended: stop count reached\")\n",
    "        else:\n",
    "            return feature_selection(df_train, df_test, feat, feats, target, params, history=history, stop=stop, count = count+1, display=display)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # create ElasticNet model with params\n",
    "        elastic = ElasticNetCV(l1_ratio=params['l1_ratio'],\n",
    "                           fit_intercept=params['fit_intercept'],\n",
    "                           alphas=params['alphas'],\n",
    "                           cv=params['cv'],\n",
    "                           n_jobs=params['n_jobs'],\n",
    "                           max_iter=params['max_iter'],\n",
    "                           random_state=params['random_state'],\n",
    "                           tol=params['tol'],\n",
    "                           verbose=params['verbose'])\n",
    "        \n",
    "        # pipeline\n",
    "        pipe = Pipeline([\n",
    "            ('model', elastic),\n",
    "        ])\n",
    "\n",
    "        # split\n",
    "        X = df_train.loc[:, feats]\n",
    "        Y = df_train[target]\n",
    "        \n",
    "        # stratify CRT scores \n",
    "        bin_count = 0\n",
    "        for i in df_train[target].value_counts() > 1:\n",
    "            if i:\n",
    "                bin_count += 1      \n",
    "        bin_count -= 1\n",
    "\n",
    "        bins = np.linspace(0, 1, bin_count)\n",
    "        y_binned = np.digitize(Y, bins)\n",
    "                \n",
    "        if display: \n",
    "            print(\"Fitting to data...\")\n",
    "\n",
    "        # fit         \n",
    "        start = time.time()\n",
    "        pipe.fit(X, Y)\n",
    "        end = time.time()\n",
    "    \n",
    "        if display: \n",
    "            print(\"Done with \" + str(round(end - start, 5)) + \" seconds\")\n",
    "\n",
    "        # generate plot for feature importance via coefficients\n",
    "        importance = np.abs(pipe['model'].coef_)\n",
    "        feature_names = np.array(df_train[feats].columns)\n",
    "\n",
    "        if np.sort(importance)[1] == 0: # drop all coefficients that are zero if zero-value coefficients exist  \n",
    "            thresh = next((x for i, x in enumerate(np.sort(importance)) if x), None)\n",
    "        else: \n",
    "            thresh = np.sort(importance)[1] # otherwise drop lowest-value coefficient\n",
    "            \n",
    "        if thresh == None:\n",
    "            print(\"Feature selection has determined that no features are relevant (i.e. all coefficients are zero).\")\n",
    "        else:\n",
    "            \n",
    "            # pipeline to select from model given threshold \n",
    "            pipe_sfm = Pipeline([\n",
    "                ('sfm', SelectFromModel(pipe['model'], threshold=thresh)),\n",
    "            ])\n",
    "\n",
    "            # choose features above certain threshold\n",
    "            sfm = pipe_sfm.fit(X, Y)\n",
    "            feature_names = np.array(df_train[feats].columns)\n",
    "            next_feat_names = feature_names[pipe_sfm['sfm'].get_support()].tolist()\n",
    "\n",
    "            # run Ridge + cross-validation on current set of target features to calculate accuracy \n",
    "            r, p, score, r_test, p_test, score_test = compute_metrics(df_train, df_test, target, next_feat_names, iters)\n",
    "            if display:\n",
    "                print(\"r: \", round(r, 5))\n",
    "                print(\"r test: \", round(r_test, 5))\n",
    "                print(\"Number of features selected by the model: \", len(next_feat_names))\n",
    "\n",
    "            # add results to history \n",
    "            history['thresholds'].append(thresh)\n",
    "            history['n_features'].append(len(feats))\n",
    "            history['r_vals'].append(r)\n",
    "            history['p_vals'].append(p)\n",
    "            history['selected_feats'].append(next_feat_names)\n",
    "            history['params'].append(pipe['model'].get_params())\n",
    "            history['ridge_score'].append(score)\n",
    "            history['r_vals_test'].append(abs(r_test))\n",
    "            history['p_vals_test'].append(abs(p_test))\n",
    "\n",
    "            # if we reach target number of features, stop feature selection\n",
    "            if len(next_feat_names) <= stop:\n",
    "                print(\"List of target features: \", next_feat_names)\n",
    "            else:\n",
    "                return feature_selection(df_train, df_test, feat, next_feat_names, target, params, history=history, stop=stop, count = count+1, display=display)\n",
    "    \n",
    "    # save feature selection results once selection is terminated \n",
    "    history['r_vals_abs'] = [abs(x) for x in history['r_vals']] # change all r values to absolute value \n",
    "    max_r_index = history['r_vals'].index(max(history['r_vals'])) # get index of max r value \n",
    "    target_feats = np.array(history['selected_feats'][max_r_index]) # get target features associated with max r value\n",
    "\n",
    "    results = {\n",
    "        'feature': feat,\n",
    "        'target_feats': target_feats,\n",
    "        'ridge_r_value': max(history['r_vals_abs']),\n",
    "        'ridge_p_value': np.array(history['p_vals'][max_r_index]),\n",
    "        'history': history,\n",
    "        'ridge_r_value_test': np.array(history['r_vals_test'][max_r_index]),\n",
    "        'ridge_p_value_test': np.array(history['p_vals_test'][max_r_index]),\n",
    "        'ridge_r_value_test_max': max(history['r_vals_test'].apply(lambda x: ))\n",
    "    }\n",
    "    \n",
    "    if display:\n",
    "        print(\"Final r value: \", results['ridge_r_value'])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc5cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "master_data_train = pd.read_csv('../data_03_07/dropped/CRT_ACC/master/master_data_train.csv')\n",
    "master_data_test = pd.read_csv('../data_03_07/dropped/CRT_ACC/master/master_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b773dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "PARAMS_FS = {\n",
    "            'l1_ratio': np.linspace(0.00001, 1, 20), # default is np.linspace(0.00001, 1, 20)\n",
    "            'fit_intercept': True, # default is True\n",
    "            'alphas': np.logspace(-1, 2, 20), # default is np.logspace(-1, 2, 20)\n",
    "            'cv': 10, # default is 10\n",
    "            'max_iter': 100000, # default is 100000\n",
    "            'random_state': 17, # default is 17\n",
    "            'n_jobs': -1, # default is -1\n",
    "            'tol': .00001, # default is .00001\n",
    "            'verbose': 0 # default is 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9eefd1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~ domains ~~~\n",
      "Running initial fitting...\n",
      "r:  0.14747\n",
      "r test:  -0.11226\n",
      "Total number of features:  132\n",
      "Fitting to data...\n",
      "Done with 1.23292 seconds\n",
      "r:  0.13658\n",
      "r test:  -0.09818\n",
      "Number of features selected by the model:  131\n",
      "Fitting to data...\n",
      "Done with 1.10005 seconds\n",
      "r:  0.16408\n",
      "r test:  -0.16255\n",
      "Number of features selected by the model:  130\n",
      "Fitting to data...\n",
      "Done with 1.75322 seconds\n",
      "r:  0.20408\n",
      "r test:  -0.10172\n",
      "Number of features selected by the model:  129\n",
      "Fitting to data...\n",
      "Done with 1.29477 seconds\n",
      "r:  0.09633\n",
      "r test:  -0.14408\n",
      "Number of features selected by the model:  128\n",
      "Fitting to data...\n",
      "Done with 1.12039 seconds\n",
      "r:  0.13793\n",
      "r test:  -0.11217\n",
      "Number of features selected by the model:  127\n",
      "Fitting to data...\n",
      "Done with 0.96959 seconds\n",
      "r:  0.14799\n",
      "r test:  -0.10515\n",
      "Number of features selected by the model:  126\n",
      "Fitting to data...\n",
      "Done with 0.94624 seconds\n",
      "r:  0.194\n",
      "r test:  -0.10783\n",
      "Number of features selected by the model:  125\n",
      "Fitting to data...\n",
      "Done with 1.00283 seconds\n",
      "r:  0.15431\n",
      "r test:  -0.09079\n",
      "Number of features selected by the model:  124\n",
      "Fitting to data...\n",
      "Done with 1.30215 seconds\n",
      "r:  0.20484\n",
      "r test:  -0.15654\n",
      "Number of features selected by the model:  123\n",
      "Fitting to data...\n",
      "Done with 1.3119 seconds\n",
      "r:  0.28817\n",
      "r test:  -0.10715\n",
      "Number of features selected by the model:  122\n",
      "Fitting to data...\n",
      "Done with 1.03181 seconds\n",
      "r:  0.19754\n",
      "r test:  -0.12605\n",
      "Number of features selected by the model:  121\n",
      "Fitting to data...\n",
      "Done with 1.27215 seconds\n",
      "r:  0.165\n",
      "r test:  -0.13666\n",
      "Number of features selected by the model:  120\n",
      "Fitting to data...\n",
      "Done with 1.25278 seconds\n",
      "r:  0.16354\n",
      "r test:  -0.05314\n",
      "Number of features selected by the model:  119\n",
      "Fitting to data...\n",
      "Done with 1.03778 seconds\n",
      "r:  0.05562\n",
      "r test:  -0.11196\n",
      "Number of features selected by the model:  118\n",
      "Fitting to data...\n",
      "Done with 1.25071 seconds\n",
      "r:  0.13222\n",
      "r test:  -0.05223\n",
      "Number of features selected by the model:  117\n",
      "Fitting to data...\n",
      "Done with 0.96456 seconds\n",
      "r:  0.11691\n",
      "r test:  -0.14902\n",
      "Number of features selected by the model:  116\n",
      "Fitting to data...\n",
      "Done with 0.91989 seconds\n",
      "r:  0.21608\n",
      "r test:  -0.10818\n",
      "Number of features selected by the model:  115\n",
      "Fitting to data...\n",
      "Done with 1.37358 seconds\n",
      "r:  0.13275\n",
      "r test:  -0.18219\n",
      "Number of features selected by the model:  114\n",
      "Fitting to data...\n",
      "Done with 1.19837 seconds\n",
      "r:  0.10833\n",
      "r test:  -0.08073\n",
      "Number of features selected by the model:  113\n",
      "Fitting to data...\n",
      "Done with 1.08103 seconds\n",
      "r:  0.19705\n",
      "r test:  -0.11282\n",
      "Number of features selected by the model:  112\n",
      "Fitting to data...\n",
      "Done with 0.98967 seconds\n",
      "r:  0.17229\n",
      "r test:  -0.13382\n",
      "Number of features selected by the model:  111\n",
      "Fitting to data...\n",
      "Done with 0.95331 seconds\n",
      "r:  0.17938\n",
      "r test:  -0.10513\n",
      "Number of features selected by the model:  110\n",
      "Fitting to data...\n",
      "Done with 1.06254 seconds\n",
      "r:  0.15584\n",
      "r test:  -0.08992\n",
      "Number of features selected by the model:  109\n",
      "Fitting to data...\n",
      "Done with 0.93679 seconds\n",
      "r:  0.2177\n",
      "r test:  -0.10207\n",
      "Number of features selected by the model:  108\n",
      "Fitting to data...\n",
      "Done with 0.93148 seconds\n",
      "r:  0.13521\n",
      "r test:  -0.12877\n",
      "Number of features selected by the model:  107\n",
      "Fitting to data...\n",
      "Done with 1.03605 seconds\n",
      "r:  0.09393\n",
      "r test:  -0.10393\n",
      "Number of features selected by the model:  106\n",
      "Fitting to data...\n",
      "Done with 1.27061 seconds\n",
      "r:  0.19757\n",
      "r test:  -0.08062\n",
      "Number of features selected by the model:  105\n",
      "Fitting to data...\n",
      "Done with 1.31038 seconds\n",
      "r:  0.18548\n",
      "r test:  -0.12302\n",
      "Number of features selected by the model:  104\n",
      "Fitting to data...\n",
      "Done with 1.04501 seconds\n",
      "r:  0.1833\n",
      "r test:  -0.10912\n",
      "Number of features selected by the model:  103\n",
      "Fitting to data...\n",
      "Done with 1.03198 seconds\n",
      "r:  0.20436\n",
      "r test:  -0.11291\n",
      "Number of features selected by the model:  102\n",
      "Fitting to data...\n",
      "Done with 1.11022 seconds\n",
      "r:  0.07951\n",
      "r test:  -0.10423\n",
      "Number of features selected by the model:  101\n",
      "Fitting to data...\n",
      "Done with 1.20934 seconds\n",
      "r:  0.27261\n",
      "r test:  -0.07468\n",
      "Number of features selected by the model:  100\n",
      "Fitting to data...\n",
      "Done with 1.32757 seconds\n",
      "r:  0.10133\n",
      "r test:  -0.09786\n",
      "Number of features selected by the model:  99\n",
      "Fitting to data...\n",
      "Done with 1.11199 seconds\n",
      "r:  0.1551\n",
      "r test:  -0.0971\n",
      "Number of features selected by the model:  98\n",
      "Fitting to data...\n",
      "Done with 0.98949 seconds\n",
      "r:  0.19062\n",
      "r test:  -0.11212\n",
      "Number of features selected by the model:  97\n",
      "Fitting to data...\n",
      "Done with 0.96868 seconds\n",
      "r:  0.16168\n",
      "r test:  -0.09108\n",
      "Number of features selected by the model:  96\n",
      "Fitting to data...\n",
      "Done with 0.92147 seconds\n",
      "r:  0.13191\n",
      "r test:  -0.14564\n",
      "Number of features selected by the model:  95\n",
      "Fitting to data...\n",
      "Done with 1.19234 seconds\n",
      "r:  0.08302\n",
      "r test:  -0.07395\n",
      "Number of features selected by the model:  94\n",
      "Fitting to data...\n",
      "Done with 1.0746 seconds\n",
      "r:  0.21871\n",
      "r test:  -0.11306\n",
      "Number of features selected by the model:  93\n",
      "Fitting to data...\n",
      "Done with 1.38703 seconds\n",
      "r:  0.15888\n",
      "r test:  -0.10284\n",
      "Number of features selected by the model:  92\n",
      "Fitting to data...\n",
      "Done with 1.34526 seconds\n",
      "r:  0.20481\n",
      "r test:  -0.15828\n",
      "Number of features selected by the model:  91\n",
      "Fitting to data...\n",
      "Done with 1.12156 seconds\n",
      "r:  0.2194\n",
      "r test:  -0.1258\n",
      "Number of features selected by the model:  90\n",
      "Fitting to data...\n",
      "Done with 1.29381 seconds\n",
      "r:  0.25238\n",
      "r test:  -0.1384\n",
      "Number of features selected by the model:  89\n",
      "Fitting to data...\n",
      "Done with 1.23917 seconds\n",
      "r:  0.29176\n",
      "r test:  -0.11779\n",
      "Number of features selected by the model:  88\n",
      "Fitting to data...\n",
      "Done with 1.1819 seconds\n",
      "r:  0.10169\n",
      "r test:  -0.18675\n",
      "Number of features selected by the model:  87\n",
      "Fitting to data...\n",
      "Done with 1.21001 seconds\n",
      "r:  0.25305\n",
      "r test:  -0.10592\n",
      "Number of features selected by the model:  86\n",
      "Fitting to data...\n",
      "Done with 1.06743 seconds\n",
      "r:  0.1659\n",
      "r test:  -0.10111\n",
      "Number of features selected by the model:  85\n",
      "Fitting to data...\n",
      "Done with 1.21044 seconds\n",
      "r:  0.19042\n",
      "r test:  -0.09598\n",
      "Number of features selected by the model:  84\n",
      "Fitting to data...\n",
      "Done with 1.61175 seconds\n",
      "r:  0.26277\n",
      "r test:  -0.08904\n",
      "Number of features selected by the model:  83\n",
      "Fitting to data...\n",
      "Done with 1.57015 seconds\n",
      "r:  0.19041\n",
      "r test:  -0.07981\n",
      "Number of features selected by the model:  82\n",
      "Fitting to data...\n",
      "Done with 1.28517 seconds\n",
      "r:  0.25615\n",
      "r test:  -0.10205\n",
      "Number of features selected by the model:  81\n",
      "Fitting to data...\n",
      "Done with 0.96442 seconds\n",
      "r:  0.20705\n",
      "r test:  -0.07467\n",
      "Number of features selected by the model:  80\n",
      "Fitting to data...\n",
      "Done with 1.56871 seconds\n",
      "r:  0.21841\n",
      "r test:  -0.0938\n",
      "Number of features selected by the model:  79\n",
      "Fitting to data...\n",
      "Done with 1.58203 seconds\n",
      "r:  0.18308\n",
      "r test:  -0.09242\n",
      "Number of features selected by the model:  78\n",
      "Fitting to data...\n",
      "Done with 1.20896 seconds\n",
      "r:  0.27434\n",
      "r test:  -0.12391\n",
      "Number of features selected by the model:  77\n",
      "Fitting to data...\n",
      "Done with 1.1027 seconds\n",
      "r:  0.29206\n",
      "r test:  -0.1645\n",
      "Number of features selected by the model:  76\n",
      "Fitting to data...\n",
      "Done with 1.42428 seconds\n",
      "r:  0.1335\n",
      "r test:  -0.09345\n",
      "Number of features selected by the model:  75\n",
      "Fitting to data...\n",
      "Done with 1.51151 seconds\n",
      "r:  0.18874\n",
      "r test:  -0.15135\n",
      "Number of features selected by the model:  74\n",
      "Fitting to data...\n",
      "Done with 1.08092 seconds\n",
      "r:  0.1265\n",
      "r test:  -0.14766\n",
      "Number of features selected by the model:  73\n",
      "Fitting to data...\n",
      "Done with 1.16138 seconds\n",
      "r:  0.17564\n",
      "r test:  -0.14159\n",
      "Number of features selected by the model:  72\n",
      "Fitting to data...\n",
      "Done with 1.07271 seconds\n",
      "r:  0.22581\n",
      "r test:  -0.12457\n",
      "Number of features selected by the model:  71\n",
      "Fitting to data...\n",
      "Done with 1.05892 seconds\n",
      "r:  0.27341\n",
      "r test:  -0.15271\n",
      "Number of features selected by the model:  70\n",
      "Fitting to data...\n",
      "Done with 1.55175 seconds\n",
      "r:  0.18984\n",
      "r test:  -0.10907\n",
      "Number of features selected by the model:  69\n",
      "Fitting to data...\n",
      "Done with 1.23852 seconds\n",
      "r:  0.31766\n",
      "r test:  -0.12826\n",
      "Number of features selected by the model:  68\n",
      "Fitting to data...\n",
      "Done with 0.95604 seconds\n",
      "r:  0.29583\n",
      "r test:  -0.14843\n",
      "Number of features selected by the model:  67\n",
      "Fitting to data...\n",
      "Done with 1.1514 seconds\n",
      "r:  0.34883\n",
      "r test:  -0.13505\n",
      "Number of features selected by the model:  66\n",
      "Fitting to data...\n",
      "Done with 1.09855 seconds\n",
      "r:  0.20386\n",
      "r test:  -0.12869\n",
      "Number of features selected by the model:  65\n",
      "Fitting to data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 1.49568 seconds\n",
      "r:  0.27692\n",
      "r test:  -0.09954\n",
      "Number of features selected by the model:  64\n",
      "Fitting to data...\n",
      "Done with 1.72116 seconds\n",
      "r:  0.18335\n",
      "r test:  -0.1223\n",
      "Number of features selected by the model:  63\n",
      "Fitting to data...\n",
      "Done with 1.19539 seconds\n",
      "r:  0.20645\n",
      "r test:  -0.10545\n",
      "Number of features selected by the model:  62\n",
      "Fitting to data...\n",
      "Done with 1.12446 seconds\n",
      "r:  0.15592\n",
      "r test:  -0.11534\n",
      "Number of features selected by the model:  61\n",
      "Fitting to data...\n",
      "Done with 1.26522 seconds\n",
      "r:  0.24625\n",
      "r test:  -0.12129\n",
      "Number of features selected by the model:  60\n",
      "Fitting to data...\n",
      "Done with 1.18572 seconds\n",
      "r:  0.34739\n",
      "r test:  -0.05104\n",
      "Number of features selected by the model:  59\n",
      "Fitting to data...\n",
      "Done with 1.42696 seconds\n",
      "r:  0.29983\n",
      "r test:  -0.1337\n",
      "Number of features selected by the model:  58\n",
      "Fitting to data...\n",
      "Done with 1.02083 seconds\n",
      "r:  0.31748\n",
      "r test:  -0.15971\n",
      "Number of features selected by the model:  57\n",
      "Fitting to data...\n",
      "Done with 1.33362 seconds\n",
      "r:  0.36212\n",
      "r test:  -0.12257\n",
      "Number of features selected by the model:  56\n",
      "Fitting to data...\n",
      "Done with 1.16287 seconds\n",
      "r:  0.27715\n",
      "r test:  -0.16704\n",
      "Number of features selected by the model:  55\n",
      "Fitting to data...\n",
      "Done with 1.31587 seconds\n",
      "r:  0.23875\n",
      "r test:  -0.12384\n",
      "Number of features selected by the model:  54\n",
      "Fitting to data...\n",
      "Done with 1.06358 seconds\n",
      "r:  0.24766\n",
      "r test:  -0.15634\n",
      "Number of features selected by the model:  53\n",
      "Fitting to data...\n",
      "Done with 1.17136 seconds\n",
      "r:  0.27387\n",
      "r test:  -0.16612\n",
      "Number of features selected by the model:  52\n",
      "Fitting to data...\n",
      "Done with 1.1259 seconds\n",
      "r:  0.29994\n",
      "r test:  -0.13336\n",
      "Number of features selected by the model:  51\n",
      "Fitting to data...\n",
      "Done with 1.87739 seconds\n",
      "r:  0.28313\n",
      "r test:  -0.13956\n",
      "Number of features selected by the model:  50\n",
      "Fitting to data...\n",
      "Done with 1.29194 seconds\n",
      "r:  0.33721\n",
      "r test:  -0.14298\n",
      "Number of features selected by the model:  49\n",
      "Fitting to data...\n",
      "Done with 1.07117 seconds\n",
      "r:  0.33825\n",
      "r test:  -0.10611\n",
      "Number of features selected by the model:  48\n",
      "Fitting to data...\n",
      "Done with 1.23351 seconds\n",
      "r:  0.28564\n",
      "r test:  -0.13335\n",
      "Number of features selected by the model:  47\n",
      "Fitting to data...\n",
      "Done with 0.9161 seconds\n",
      "r:  0.2352\n",
      "r test:  -0.12396\n",
      "Number of features selected by the model:  46\n",
      "Fitting to data...\n",
      "Done with 1.21201 seconds\n",
      "r:  0.08565\n",
      "r test:  -0.13548\n",
      "Number of features selected by the model:  45\n",
      "Fitting to data...\n",
      "Done with 1.34095 seconds\n",
      "r:  0.29622\n",
      "r test:  -0.1279\n",
      "Number of features selected by the model:  44\n",
      "Fitting to data...\n",
      "Done with 1.36379 seconds\n",
      "r:  0.27325\n",
      "r test:  -0.12072\n",
      "Number of features selected by the model:  43\n",
      "Fitting to data...\n",
      "Done with 1.09184 seconds\n",
      "r:  0.32789\n",
      "r test:  -0.15523\n",
      "Number of features selected by the model:  42\n",
      "Fitting to data...\n",
      "Done with 0.96008 seconds\n",
      "r:  0.26953\n",
      "r test:  -0.15084\n",
      "Number of features selected by the model:  41\n",
      "Fitting to data...\n",
      "Done with 0.88989 seconds\n",
      "r:  0.24715\n",
      "r test:  -0.11424\n",
      "Number of features selected by the model:  40\n",
      "Fitting to data...\n",
      "Done with 1.12 seconds\n",
      "r:  0.28173\n",
      "r test:  -0.15009\n",
      "Number of features selected by the model:  39\n",
      "Fitting to data...\n",
      "Done with 1.17504 seconds\n",
      "r:  0.20943\n",
      "r test:  -0.13847\n",
      "Number of features selected by the model:  38\n",
      "Fitting to data...\n",
      "Done with 1.25817 seconds\n",
      "r:  0.2507\n",
      "r test:  -0.17302\n",
      "Number of features selected by the model:  37\n",
      "Fitting to data...\n",
      "Done with 1.02278 seconds\n",
      "r:  0.31514\n",
      "r test:  -0.15858\n",
      "Number of features selected by the model:  36\n",
      "Fitting to data...\n",
      "Done with 0.88668 seconds\n",
      "r:  0.33928\n",
      "r test:  -0.15933\n",
      "Number of features selected by the model:  35\n",
      "Fitting to data...\n",
      "Done with 0.98867 seconds\n",
      "r:  0.2808\n",
      "r test:  -0.10825\n",
      "Number of features selected by the model:  34\n",
      "Fitting to data...\n",
      "Done with 1.04099 seconds\n",
      "r:  0.43009\n",
      "r test:  -0.12049\n",
      "Number of features selected by the model:  33\n",
      "Fitting to data...\n",
      "Done with 0.91977 seconds\n",
      "r:  0.25871\n",
      "r test:  -0.11761\n",
      "Number of features selected by the model:  32\n",
      "Fitting to data...\n",
      "Done with 0.91217 seconds\n",
      "r:  0.28523\n",
      "r test:  -0.12016\n",
      "Number of features selected by the model:  31\n",
      "Fitting to data...\n",
      "Done with 0.96249 seconds\n",
      "r:  0.25174\n",
      "r test:  -0.12559\n",
      "Number of features selected by the model:  30\n",
      "Fitting to data...\n",
      "Done with 0.87262 seconds\n",
      "r:  0.28403\n",
      "r test:  -0.14143\n",
      "Number of features selected by the model:  29\n",
      "Fitting to data...\n",
      "Done with 1.20254 seconds\n",
      "r:  0.29321\n",
      "r test:  -0.13598\n",
      "Number of features selected by the model:  28\n",
      "Fitting to data...\n",
      "Done with 1.34359 seconds\n",
      "r:  0.16496\n",
      "r test:  -0.12605\n",
      "Number of features selected by the model:  27\n",
      "Fitting to data...\n",
      "Done with 1.42491 seconds\n",
      "r:  0.28918\n",
      "r test:  -0.14558\n",
      "Number of features selected by the model:  26\n",
      "Fitting to data...\n",
      "Done with 1.15929 seconds\n",
      "r:  0.26877\n",
      "r test:  -0.15642\n",
      "Number of features selected by the model:  25\n",
      "Fitting to data...\n",
      "Done with 1.05947 seconds\n",
      "r:  0.20846\n",
      "r test:  -0.11297\n",
      "Number of features selected by the model:  24\n",
      "Fitting to data...\n",
      "Done with 1.20129 seconds\n",
      "r:  0.14767\n",
      "r test:  -0.13688\n",
      "Number of features selected by the model:  23\n",
      "Fitting to data...\n",
      "Done with 0.90855 seconds\n",
      "r:  0.30924\n",
      "r test:  -0.13925\n",
      "Number of features selected by the model:  22\n",
      "Fitting to data...\n",
      "Done with 1.19806 seconds\n",
      "r:  0.24159\n",
      "r test:  -0.16727\n",
      "Number of features selected by the model:  21\n",
      "Fitting to data...\n",
      "Done with 1.29765 seconds\n",
      "r:  0.33871\n",
      "r test:  -0.14505\n",
      "Number of features selected by the model:  20\n",
      "Fitting to data...\n",
      "Done with 1.23237 seconds\n",
      "r:  0.17609\n",
      "r test:  -0.15309\n",
      "Number of features selected by the model:  19\n",
      "Fitting to data...\n",
      "Done with 1.6368 seconds\n",
      "r:  0.251\n",
      "r test:  -0.13217\n",
      "Number of features selected by the model:  18\n",
      "Fitting to data...\n",
      "Done with 2.00922 seconds\n",
      "r:  0.22762\n",
      "r test:  -0.18381\n",
      "Number of features selected by the model:  17\n",
      "Fitting to data...\n",
      "Done with 2.20901 seconds\n",
      "r:  0.35554\n",
      "r test:  -0.18217\n",
      "Number of features selected by the model:  16\n",
      "Fitting to data...\n",
      "Done with 1.6154 seconds\n",
      "r:  0.24687\n",
      "r test:  -0.15828\n",
      "Number of features selected by the model:  15\n",
      "Fitting to data...\n",
      "Done with 1.39414 seconds\n",
      "r:  0.22555\n",
      "r test:  -0.17005\n",
      "Number of features selected by the model:  14\n",
      "Fitting to data...\n",
      "Done with 1.36996 seconds\n",
      "r:  0.25547\n",
      "r test:  -0.18691\n",
      "Number of features selected by the model:  13\n",
      "Fitting to data...\n",
      "Done with 1.66389 seconds\n",
      "r:  0.24684\n",
      "r test:  -0.13928\n",
      "Number of features selected by the model:  12\n",
      "Fitting to data...\n",
      "Done with 1.06028 seconds\n",
      "r:  0.29806\n",
      "r test:  -0.12553\n",
      "Number of features selected by the model:  11\n",
      "Fitting to data...\n",
      "Done with 0.86129 seconds\n",
      "r:  0.23214\n",
      "r test:  -0.12078\n",
      "Number of features selected by the model:  10\n",
      "Fitting to data...\n",
      "Done with 0.81982 seconds\n",
      "r:  0.26125\n",
      "r test:  -0.12751\n",
      "Number of features selected by the model:  9\n",
      "Fitting to data...\n",
      "Done with 0.82618 seconds\n",
      "r:  0.17049\n",
      "r test:  -0.15335\n",
      "Number of features selected by the model:  8\n",
      "Fitting to data...\n",
      "Done with 0.84344 seconds\n",
      "r:  0.30409\n",
      "r test:  -0.13267\n",
      "Number of features selected by the model:  7\n",
      "Fitting to data...\n",
      "Done with 0.81556 seconds\n",
      "r:  -0.0175\n",
      "r test:  -0.1233\n",
      "Number of features selected by the model:  6\n",
      "Fitting to data...\n",
      "Done with 0.67424 seconds\n",
      "r:  0.07366\n",
      "r test:  -0.08098\n",
      "Number of features selected by the model:  5\n",
      "Fitting to data...\n",
      "Done with 0.62071 seconds\n",
      "r:  0.16513\n",
      "r test:  -0.0894\n",
      "Number of features selected by the model:  4\n",
      "Fitting to data...\n",
      "Done with 0.54824 seconds\n",
      "r:  0.2371\n",
      "r test:  -0.07629\n",
      "Number of features selected by the model:  3\n",
      "Fitting to data...\n",
      "Done with 0.55201 seconds\n",
      "r:  0.10658\n",
      "r test:  -0.06222\n",
      "Number of features selected by the model:  2\n",
      "Fitting to data...\n",
      "Done with 0.65173 seconds\n",
      "r:  0.24042\n",
      "r test:  -0.04555\n",
      "Number of features selected by the model:  1\n",
      "List of target features:  ['domains_3']\n",
      "Final r value:  0.4300946525028877\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Figure' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2q/vh0xdtm50wvcxd06f5wfh3l00000gn/T/ipykernel_17288/4114176105.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mselection_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mselection_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CRT_ACC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dropped'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mgeneral\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_background\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#fff9e9'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Figure' object is not callable"
     ]
    }
   ],
   "source": [
    "# run this cell to perform feature selection\n",
    "feat_dict = split_columns(master_data_train, \"CRT_ACC\")\n",
    "selection_results = pd.DataFrame(columns=['feature', 'target_feats', 'ridge_r_value', 'ridge_p_value', 'history'])\n",
    "\n",
    "for feat, featlist in feat_dict.items():\n",
    "    \n",
    "    if feat != 'domains':\n",
    "        continue\n",
    "        \n",
    "    # do not perform feature selection on CRT score\n",
    "    if feat.startswith(\"CRT\"):\n",
    "        continue\n",
    "\n",
    "    results = feature_selection(master_data_train, master_data_test, feat, featlist, 'CRT_ACC', PARAMS_FS, \n",
    "                                          stop=1, display=True, iters=10)\n",
    "    selection_results = selection_results.append(results, ignore_index=True)\n",
    "\n",
    "selection_df, plot, chart = plot(selection_results, 'test', 'CRT_ACC', 'dropped', True)\n",
    "\n",
    "general.set_background('#fff9e9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f90de42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>target_feats</th>\n",
       "      <th>ridge_r_value</th>\n",
       "      <th>ridge_p_value</th>\n",
       "      <th>history</th>\n",
       "      <th>ridge_p_value_test</th>\n",
       "      <th>ridge_r_value_test</th>\n",
       "      <th>ridge_r_value_test_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>domains</td>\n",
       "      <td>[domains_2, domains_3, domains_8, domains_10, ...</td>\n",
       "      <td>0.430095</td>\n",
       "      <td>4.881906725086057e-08</td>\n",
       "      <td>{'r_vals': [0.1474693961159719, 0.136583135538...</td>\n",
       "      <td>0.10139693901201781</td>\n",
       "      <td>-0.12048694943736409</td>\n",
       "      <td>-0.045555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature                                       target_feats  ridge_r_value  \\\n",
       "0  domains  [domains_2, domains_3, domains_8, domains_10, ...       0.430095   \n",
       "\n",
       "           ridge_p_value                                            history  \\\n",
       "0  4.881906725086057e-08  {'r_vals': [0.1474693961159719, 0.136583135538...   \n",
       "\n",
       "    ridge_p_value_test    ridge_r_value_test  ridge_r_value_test_max  \n",
       "0  0.10139693901201781  -0.12048694943736409               -0.045555  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9428bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function runs Ridge with cross-validation on dataframe and selected features\n",
    "\n",
    "Inputs:\n",
    "df (pandas df): master dataframe\n",
    "target (string): CRT target feature (numeric, conceptual, or both)\n",
    "selected_feats (list): selected feature names as strings\n",
    "iters (integer): number of iterations to perform Ridge + cross validation\n",
    "\n",
    "Outputs:\n",
    "r_avg (float): r value from Pearson correlation, averaged across all iterations\n",
    "p_avg (float): p value from Pearson correlation, averaged across all iterations\n",
    "score_avg (float): R^2 score from Ridge regression, averaged across all iterations\n",
    "\"\"\"\n",
    "def compute_metrics(df_train, df_test, target, selected_feats, iters):\n",
    "    \n",
    "    total_r = 0\n",
    "    total_p = 0\n",
    "    total_score = 0\n",
    "    \n",
    "    total_r_test = 0\n",
    "    total_p_test = 0\n",
    "    total_score_test = 0\n",
    "        \n",
    "    X = df_train[selected_feats]\n",
    "    Y = df_train[target]\n",
    "    \n",
    "    X_real_test = df_test[selected_feats]\n",
    "    Y_real_test = df_test[target]\n",
    "    \n",
    "    # stratify CRT scores \n",
    "    bin_count = 0\n",
    "    for i in df_train[target].value_counts() > 1:\n",
    "        if i:\n",
    "            bin_count += 1      \n",
    "    bin_count -= 1\n",
    "\n",
    "    bins = np.linspace(0, 1, bin_count)\n",
    "    y_binned = np.digitize(Y, bins)\n",
    "    \n",
    "    for num in range(iters):\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=y_binned)\n",
    "\n",
    "        grid = GridSearchCV(Ridge(), param_grid={'alpha': np.logspace(-5,5,100)}, cv=5, n_jobs=1, verbose=0, scoring='neg_mean_squared_error')\n",
    "\n",
    "        grid.fit(X_train, Y_train)\n",
    "        y_pred = grid.predict(X_test)\n",
    "        y_pred=np.maximum(0, np.minimum(y_pred, 1))\n",
    "        r, p = pearsonr(y_pred, Y_test)\n",
    "        score = grid.best_score_\n",
    "        \n",
    "        y_pred_real = grid.predict(X_real_test)\n",
    "        y_pred_real=np.maximum(0, np.minimum(y_pred_real, 1))\n",
    "        r_test, p_test = pearsonr(y_pred_real, Y_real_test)\n",
    "        score_test = grid.best_score_\n",
    "        \n",
    "        total_r += r\n",
    "        total_p += p\n",
    "        total_score += score\n",
    "        \n",
    "        total_r_test += r_test\n",
    "        total_p_test += p_test\n",
    "        total_score_test += score_test\n",
    "    \n",
    "    r_avg = total_r/iters\n",
    "    p_avg = total_p/iters\n",
    "    score_avg = total_score/iters\n",
    "    \n",
    "    r_avg_test = total_r_test/iters\n",
    "    p_avg_test = total_p_test/iters\n",
    "    score_avg_test = total_score_test/iters\n",
    "    \n",
    "    return (r_avg, p_avg, score_avg, r_avg_test, p_avg_test, score_avg_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afbb82dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function splits up all dataframe columns into a dictionary of lists\n",
    "\n",
    "Inputs:\n",
    "data (pandas df): master dataframe\n",
    "target (string): CRT target feature (numeric, conceptual, or both)\n",
    "\n",
    "Outputs: \n",
    "feat_dict (dictionary): organized predictors by feature name {feature_name: [predictor_1, predictor_2]}, \n",
    "                        such as {text: [text_1, text_2, ..., text_200]}\n",
    "\"\"\"\n",
    "def split_columns(data, target):\n",
    "    feat_dict = {}\n",
    "\n",
    "    df_columns = list(data.columns)\n",
    "    df_columns.remove('screen_name')\n",
    "    df_columns.remove(target)\n",
    "\n",
    "    for col in df_columns:\n",
    "        names = col.split(\"_\")\n",
    "        try: \n",
    "            int(names[-1])\n",
    "            name = \"_\".join(names[:-1])\n",
    "        except:\n",
    "            name = \"_\".join(names)\n",
    "\n",
    "        if name not in feat_dict:\n",
    "            feat_dict[name] = [col]\n",
    "        else:\n",
    "            feat_dict[name].append(col)\n",
    "    \n",
    "    return feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46cef75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function creates a dataframe organized by decreasing best r value and plots results\n",
    "\n",
    "Inputs:\n",
    "selection_df (pandas df): dataframe with feature selection results\n",
    "path (string): path to feature selection results folder\n",
    "target (string): CRT target feature (numeric, conceptual, or both)\n",
    "dataframe_type (string): dropped or imputed\n",
    "display (boolean): if True, display plot and chart\n",
    "\n",
    "Outputs:\n",
    "selection_df (pandas df): dataframe with feature selection results, sorted by decreasing r value\n",
    "ax (plot): plot of selection results, sorted by decreasing r value\n",
    "chart (plotly): chart displaying feature selection results\n",
    "\"\"\"\n",
    "def plot(selection_df_, path, target, dataframe_type, display=True):\n",
    "    # sort in reverse order r value \n",
    "    selection_df = selection_df_.sort_values('ridge_r_value')[::-1]\n",
    "\n",
    "    isExist = os.path.exists(path)\n",
    "    if not isExist:\n",
    "        os.makedirs(path)\n",
    "    selection_df.to_pickle(path + 'selection_df.pickle')\n",
    "    \n",
    "    selection_df_dropped = selection_df.dropna()\n",
    "    \n",
    "    # plot results\n",
    "    ax, chart = create_plotly(selection_df_dropped, target, dataframe_type)\n",
    "    \n",
    "    if display:\n",
    "        ax.show()\n",
    "        chart.show()\n",
    "    \n",
    "    ax.write_html(path + \"selection_plot.html\")\n",
    "    chart.write_html(path + \"selection_chart.html\")\n",
    "\n",
    "    return (selection_df, ax, chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32fa109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function generates a plotly plot and chart from feature selection.\n",
    "\n",
    "Inputs:\n",
    "df (pandas df): dataframe with feature selection results, sorted by decreasing r value\n",
    "target (string): CRT target feature (numeric, conceptual, or both)\n",
    "dataframe_type (string): dropped or imputed\n",
    "\n",
    "Outputs: \n",
    "fig (plotly): plot displaying feature selection results\n",
    "chart (plotly): chart displaying feature selection results\n",
    "\"\"\"\n",
    "def create_plotly(df, target, dataframe_type):\n",
    "    \n",
    "    textfeat = ['mentions', 'text', 'domains', 'bio', 'followees', 'follower_bios', 'followee_bios',\n",
    "           'hashtags']\n",
    "    \n",
    "    # create plot\n",
    "    df_plot = df.sort_values(by=[\"ridge_r_value\"], ascending=True)\n",
    "    \n",
    "    fig = go.Figure(go.Bar(\n",
    "                y=df_plot['feature'],\n",
    "                x=df_plot['ridge_r_value'],\n",
    "                orientation='h',\n",
    "                text=df_plot['ridge_r_value'].apply(lambda x: \"{:.2f}\".format(x)),\n",
    "                textposition='auto',\n",
    "                marker_color=['salmon' if col in textfeat else 'lightslategray' for col in df_plot['feature']]\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        yaxis_title=\"Feature Name\",\n",
    "        xaxis_title=\"Absolute R Value from Ridge\",\n",
    "        font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            size=10,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "        tickmode='linear'),\n",
    "\n",
    "        width=1000, height=800,\n",
    "\n",
    "        title={\n",
    "            'text': \"Feature Selection Correlations (Target: {}; Data: {})\".format(target, dataframe_type),\n",
    "            'y':.92,\n",
    "            'x':0.5,\n",
    "            'font': dict(\n",
    "                size=22,\n",
    "            ),\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'}\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(title_font_size=15)\n",
    "    fig.update_xaxes(title_font_size=15)\n",
    "\n",
    "    fig.update_traces(textposition='outside', textfont_size=10)\n",
    "    \n",
    "    # create chart\n",
    "    chart = go.Figure(data=[go.Table(\n",
    "    header=dict(values=['Features', 'R Value', 'P Value', 'R Value Test', 'P Value Test', 'R Value Test Max'],\n",
    "                fill_color='darksalmon',\n",
    "                align='left'),\n",
    "    cells=dict(values=[df.feature, df.ridge_r_value.apply(lambda x: \"{:.5f}\".format(x)),\n",
    "                      df.ridge_p_value.apply(lambda x: \"{:.5f}\".format(x)),\n",
    "                      df.ridge_r_value_test.apply(lambda x: \"{:.5f}\".format(x)),\n",
    "                      df.ridge_p_value_test.apply(lambda x: \"{:.5f}\".format(x)), \n",
    "                      df.ridge_r_value_test_max.apply(lambda x: \"{:.5f}\".format(x))],\n",
    "               fill_color='lightgray',\n",
    "               align='left'))\n",
    "    ])\n",
    "    \n",
    "    chart.update_layout(\n",
    "    title={\n",
    "            'text': \"Feature Selection Correlations (Target: {}; Data: {})\".format(target, dataframe_type),\n",
    "            'y':.89,\n",
    "            'x':0.5,\n",
    "            'font': dict(\n",
    "                size=22,\n",
    "            ),\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'},\n",
    "    font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            color=\"black\",\n",
    "            size=12\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return (fig, chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522dae47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
