{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c897208a",
   "metadata": {},
   "source": [
    "# This script performs hyperparameter tuning for feature extraction (TF-IDF) and dimensionality reduction (TruncatedSVD) methods for text features. The text features are domains, mentions, hashtags, followees, and text (Tweets and Retweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ad4c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import os\n",
    "\n",
    "# extraction methods\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# reduction methods \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# pipeline components\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882efc6d",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "163878f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function runs the Ridge model with cross-validation on selected dataframe and selected features.\n",
    "\n",
    "Inputs:\n",
    "data (pandas dataframe): target dataframe \n",
    "feat (string): single target feature\n",
    "target (string): CRT target feature (numeric, conceptual, or both)\n",
    "iters (integer): number of iterations to perform Ridge + cross validation\n",
    "my_min (int, float): TF-IDF min_df parameter, default set to 10\n",
    "my_components (integer): TruncatedSVD n_components parameter, default set to 20 \n",
    "\n",
    "Outputs:\n",
    "r_avg (float): r value from Pearson correlation, averaged across all iterations\n",
    "p_avg (float): p value from Pearson correlation, averaged across all iterations\n",
    "best_params (dictionary): best Ridge model parameters \n",
    "\"\"\"\n",
    "\n",
    "def model_tuning(data, feat, target, iters=1, my_components=200, my_min=1):\n",
    "    \n",
    "    total_r = 0\n",
    "    total_p = 0\n",
    "    \n",
    "    # choose TF-IDF vectorizer parameter depending on input\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,1), max_df = 1.0, min_df=my_min, use_idf=True,binary=False)\n",
    "\n",
    "    svd = TruncatedSVD(n_components=my_components, random_state=17)\n",
    "        \n",
    "    pipe = Pipeline([\n",
    "        ('model', Ridge()),\n",
    "    ])\n",
    "    \n",
    "    # set X and Y where X is transformed feature and Y is CRT score\n",
    "    X = svd.fit_transform(vectorizer.fit_transform(data[feat]))\n",
    "    Y = data[target]\n",
    "    \n",
    "    # stratify CRT scores \n",
    "    bin_count = 0\n",
    "    for i in data[target].value_counts() > 1:\n",
    "        if i:\n",
    "            bin_count += 1      \n",
    "    bin_count -= 1\n",
    "\n",
    "    bins = np.linspace(0, 1, bin_count)\n",
    "    y_binned = np.digitize(Y, bins)\n",
    "    \n",
    "    # run Ridge regression with cross-validation for iters and average results\n",
    "    for num in range(iters):\n",
    "        X_train, X_test, Y_train, Y_test  = train_test_split(X, Y, test_size=0.2, stratify=y_binned)\n",
    "\n",
    "        grid = GridSearchCV(pipe, param_grid={'model__alpha': np.logspace(-5,5,100)}, cv=5, n_jobs=1, verbose=0, scoring='neg_mean_squared_error')\n",
    "        grid.fit(X_train, Y_train)\n",
    "        y_pred = grid.predict(X_test)\n",
    "        y_pred=np.maximum(0, np.minimum(y_pred, 1))\n",
    "\n",
    "        r, p = (pearsonr(Y_test, y_pred))\n",
    "        total_r += r\n",
    "        total_p += p\n",
    "    \n",
    "    r_avg = total_r/iters\n",
    "    p_avg = total_p/iters\n",
    "    best_params = grid.best_params_\n",
    "    \n",
    "    return (r_avg, p_avg, best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833a0bda",
   "metadata": {},
   "source": [
    "# Tune Number of Components (TruncatedSVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "426d4733",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function tunes n_components parameter in TruncatedSVD.\n",
    "\n",
    "Inputs:\n",
    "df (pandas df): master dataframe\n",
    "feature (string): single target feature name\n",
    "target (string): CRT target feature (numeric, conceptual, or both)\n",
    "start (integer): n_components start value \n",
    "end (integer): n_components end value \n",
    "interval (integer): skip value \n",
    "iterations (integer): number of iterations to perform Ridge + cross validation\n",
    "results_folder (string): name of folder to save results \n",
    "\n",
    "Outputs:\n",
    "history (dictionary): history of tuning, containing history of {n_components, r value, \n",
    "                      p value, and alpha value from Ridge regression}\n",
    "\"\"\"\n",
    "def tune_feature(df, feature, target, start, end, interval, iterations, results_folder):\n",
    "    \n",
    "    # initialize history \n",
    "    history = {\n",
    "        'n_components': [],\n",
    "        'r_value': [],\n",
    "        'p_value': [],\n",
    "        'alpha': []\n",
    "    }\n",
    "    \n",
    "    count = 0\n",
    "    progress_benchmark = (float(end - start) / interval * 0.25)\n",
    "    \n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    print(\"Starting {}...\".format(feature))\n",
    "    \n",
    "    # run model tuning for ever n_components within start-end range with interval value\n",
    "    for n in range(start, end, interval):\n",
    "\n",
    "        # print progress\n",
    "        if count >= progress_benchmark:\n",
    "            print(\"{:0.2f}% complete\".format(100*(n - start) / float(end - start)))\n",
    "            progress_benchmark += (float(end - start) / interval * 0.25)\n",
    "\n",
    "        df_dropped = df[df[feature].notnull()] # drop any rows that have NaN values \n",
    "        r, p, params = model_tuning(df_dropped, feature, target, iters=iterations, my_components=n)\n",
    "\n",
    "        # save results to history\n",
    "        history['n_components'].append(n)\n",
    "        history['r_value'].append(r)\n",
    "        history['p_value'].append(p)\n",
    "        history['alpha'].append(params['model__alpha'])\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    # Check whether the specified path exists or not\n",
    "    isExist = os.path.exists(results_folder)\n",
    "    if not isExist:\n",
    "        os.makedirs(results_folder)\n",
    "    \n",
    "    # create results path with feature name\n",
    "    results_path = results_folder + \"/{}.pickle\".format(feature)\n",
    "    \n",
    "    # save history\n",
    "    with open(results_path, 'wb') as handle:\n",
    "        pickle.dump(history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    return history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77bc32c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function annotates the maximum y value on a graph. \n",
    "\n",
    "Inputs:\n",
    "x (list): all x values\n",
    "y (list): all y values\n",
    "xlabel (string): n_components or min_df \n",
    "\n",
    "Outputs: \n",
    "None\n",
    "\n",
    "Source: https://stackoverflow.com/questions/43374920/how-to-automatically-annotate-maximum-value-in-pyplot/43375405\n",
    "\"\"\"\n",
    "\n",
    "def annot_max(x,y, xlabel, ax=None):\n",
    "    xmax = x[np.argmax(y)]\n",
    "    ymax = max(y)\n",
    "    text= \"{}={:.0f}, r={:.3f}\".format(xlabel, xmax, ymax)\n",
    "    if not ax:\n",
    "        ax=plt.gca()\n",
    "    bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
    "    arrowprops=dict(arrowstyle=\"->\",connectionstyle=\"angle,angleA=0,angleB=60\")\n",
    "    kw = dict(xycoords='data',textcoords=\"axes fraction\",\n",
    "              arrowprops=arrowprops, bbox=bbox_props, ha=\"right\", va=\"top\")\n",
    "    ax.annotate(text, xy=(xmax, ymax), xytext=(0.94,0.96), **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e965d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function plots the tuning history and saves plot.\n",
    "\n",
    "Inputs:\n",
    "history (dictionary): tuning history\n",
    "x (string): name of target parameter, either min_df or n_components\n",
    "feature (string): name of feature\n",
    "\n",
    "Outputs: \n",
    "None\n",
    "\"\"\"\n",
    "def get_r_plot(history, x, feature, results_folder):\n",
    "    plt.plot(history[x], history['r_value'])\n",
    "    plt.title(\"r value by {} ({})\".format(x, feature))\n",
    "    plt.xlabel(x, fontsize=12)\n",
    "    plt.ylabel('r value', fontsize=12)\n",
    "    \n",
    "    # Check whether the specified path exists or not\n",
    "    isExist = os.path.exists(results_folder)\n",
    "    if not isExist:\n",
    "        os.makedirs(results_folder)\n",
    "    \n",
    "    annot_max(history[x], history['r_value'], x)\n",
    "    plt.savefig(results_folder + \"{}.png\".format(feature))\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6684f106",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function gets the top n_components or min_df by r value.\n",
    "\n",
    "Inputs:\n",
    "history (dictionary): dictionary of tuning history\n",
    "x (string): name of target parameter, either min_df or n_components\n",
    "k (integer): number of top results to return\n",
    "\n",
    "Outputs: \n",
    "top_values (list): top k values \n",
    "\"\"\"\n",
    "def get_top_components(history, x, k=10):\n",
    "    \n",
    "    top = sorted(range(len(history['r_value'])), key=lambda i: history['r_value'][i])\n",
    "    top.reverse()\n",
    "    best_indices = top[:k]\n",
    "    \n",
    "    top_values = [history[x][c] for c in best_indices]\n",
    "    \n",
    "    return top_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5f078e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function gets the best n_component or min_df for a given feature.\n",
    "\n",
    "Inputs:\n",
    "feature (string): single feature name \n",
    "\n",
    "Outputs: \n",
    "best_component (list): n_component values that produces the highest r value\n",
    "\"\"\"\n",
    "def get_optimal_mappings(feature, results_folder, parameter):\n",
    "    \n",
    "    # create results path with feature name\n",
    "    results_path = results_folder + \"{}.pickle\".format(feature)\n",
    "     \n",
    "    with open(results_path, 'rb') as pickle_file:\n",
    "        history = pickle.load(pickle_file)\n",
    "        \n",
    "    best_component = get_top_components(history, parameter, k=10)\n",
    "        \n",
    "    return best_component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ed503f",
   "metadata": {},
   "source": [
    "# Tune Min DF (TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9989168",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function gets the maximum min_df given best n_components for TruncatedSVD\n",
    "\n",
    "Inputs:\n",
    "data (pandas df): master dataframe\n",
    "feat (string): single target feature\n",
    "my_components (integer): best n_components for TruncatedSVD given tuning\n",
    "low (integer): lowest value for min_df\n",
    "high (integer): highest value for min_df\n",
    "\n",
    "Outputs:\n",
    "my_min (integer): maximum min_df for TF-IDF to try in order to keep appropriate dimensions\n",
    "\"\"\"\n",
    "\n",
    "def get_max_min(data, feat, my_components, low=1, high=1000):\n",
    "     \n",
    "    if high - low <= 1: # difference of 1 \n",
    "        my_min = low \n",
    "        return low\n",
    "    \n",
    "    my_min = (high + low) // 2\n",
    "\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,1),max_df= 1.0,min_df = my_min,use_idf=True, binary=False)\n",
    "    data_dropped = data[data[feat].notnull()]\n",
    "    \n",
    "    try:\n",
    "        out = vectorizer.fit_transform(data_dropped[feat])\n",
    "    except:\n",
    "        return get_max_min(data_dropped, feat, my_components, low, my_min - 1)\n",
    "    \n",
    "    n_features = len(vectorizer.get_feature_names_out())\n",
    "\n",
    "    if my_components < n_features:\n",
    "        return get_max_min(data_dropped, feat, my_components, my_min + 1, high)\n",
    "    else: \n",
    "        return get_max_min(data_dropped, feat, my_components, low, my_min - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e3eca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function tunes min_df in TF-IDF.\n",
    "\n",
    "Inputs:\n",
    "df (pandas df): master dataframe\n",
    "feature (string): single target feature name\n",
    "target (string): CRT target feature (numeric, conceptual, or both)\n",
    "svd (integer): n_components value for TruncatedSVD\n",
    "start (integer): n_components start value \n",
    "end (integer): n_components end value \n",
    "increments (integer): number of min_df to test\n",
    "iterations (integer): number of iterations to perform Ridge + cross validation\n",
    "results_folder (string): name of folder to save results \n",
    "\n",
    "Outputs:\n",
    "history (dictionary): tuning history, containing {min_df and r value}\n",
    "\"\"\"\n",
    "\n",
    "def tune_min_df(df, feature, target, svd, start, end, increments, iterations, results_folder):\n",
    "    \n",
    "    history = {\n",
    "        'r_value': [],\n",
    "        'min_df': []\n",
    "    }\n",
    "    \n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    print(\"Starting {}...\".format(feature))\n",
    "    \n",
    "    if increments >= (end - start):\n",
    "        interval = 1\n",
    "    else:\n",
    "        interval = (end - start) // increments\n",
    "    \n",
    "    count = 0\n",
    "    progress_benchmark = (float(end - start) / interval * 0.25)\n",
    "    \n",
    "    # for min_df in range start to end \n",
    "    for val in range(start, end, interval):\n",
    "        \n",
    "        if count >= progress_benchmark:\n",
    "            print(\"{:0.2f}% complete\".format(100*(val - start) / float(end - start)))\n",
    "            progress_benchmark += (float(end - start) / interval * 0.25)\n",
    "        \n",
    "        df_dropped = df[df[feature].notnull()] # drop any rows that have NaN values \n",
    "        r, p, params = model_tuning(df_dropped, feature, target, iters=iterations, my_components=svd, my_min=val)    \n",
    "        \n",
    "        # save history \n",
    "        history['r_value'].append(r)\n",
    "        history['min_df'].append(val)\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    # Check whether the specified path exists or not\n",
    "    isExist = os.path.exists(results_folder)\n",
    "    if not isExist:\n",
    "        os.makedirs(results_folder)\n",
    "        \n",
    "    # create results path with feature name\n",
    "    results_path = results_folder + \"/{}.pickle\".format(feature)\n",
    "\n",
    "    # save history\n",
    "    with open(results_path, 'wb') as handle:\n",
    "        pickle.dump(history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d61ad5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
